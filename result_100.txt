Correlation Feature Selector with selection method=variance completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7692917547568711, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8333333333333334

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7760570824524312, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8333333333333334

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7236786469344609, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.6276427061310782, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7441860465116279, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=100):
Best accuracy: 0.7535412262156447, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.8076923076923077

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7464587737843552, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7395348837209302, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.782051282051282

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7669661733615222, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.782051282051282

Correlation Feature Selector with selection method=cardinality completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7693446088794925, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8333333333333334

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7737315010570824, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8333333333333334

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7257928118393235, best hyperparameter: {'class_weight': None, 'max_depth': None}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.6346723044397463, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7510042283298097, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=100):
Best accuracy: 0.755813953488372, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.8076923076923077

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7489429175475687, best hyperparameter: {'estimator': None, 'n_estimators': 100}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7463002114164906, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7692307692307693

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7486257928118395, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.8333333333333334

Statistical Feature Selector with method=mi completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7875264270613107, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.8589743589743589

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7967758985200846, best hyperparameter: {'alpha': 1, 'max_iter': None}
Accuracy on test set: 0.8717948717948718

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7256342494714587, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7051282051282052

Result of KNeighborsClassifier():
Best accuracy: 0.7327167019027484, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.7051282051282052

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7829809725158562, best hyperparameter: {'solver': 'lsqr'}
Accuracy on test set: 0.8589743589743589

Result of SVC(random_state=100):
Best accuracy: 0.7943446088794925, best hyperparameter: {'C': 5, 'kernel': 'rbf'}
Accuracy on test set: 0.8205128205128205

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.789799154334038, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8974358974358975

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7761627906976744, best hyperparameter: {'max_depth': 5, 'n_estimators': 80}
Accuracy on test set: 0.8076923076923077

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7897463002114165, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.8205128205128205

Statistical Feature Selector with method=anova completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7875792811839324, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.8589743589743589

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7945031712473571, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.8333333333333334

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7373150105708246, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7564102564102564

Result of KNeighborsClassifier():
Best accuracy: 0.6549682875264271, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.6410256410256411

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7830866807610993, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8333333333333334

Result of SVC(random_state=100):
Best accuracy: 0.7693446088794925, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.8461538461538461

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7646934460887949, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8205128205128205

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7441331923890064, best hyperparameter: {'max_depth': 5, 'n_estimators': 80}
Accuracy on test set: 0.782051282051282

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7692389006342495, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.8076923076923077

Step Forward Feature Selection with LogisticRegression(random_state=100) to select 5 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7762156448202959, best hyperparameter: {'C': 10, 'max_iter': 50}
Accuracy on test set: 0.7564102564102564

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7533826638477801, best hyperparameter: {'alpha': 5, 'max_iter': None}
Accuracy on test set: 0.7564102564102564

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7213002114164906, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6666666666666666

Result of KNeighborsClassifier():
Best accuracy: 0.7557610993657505, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.6794871794871795

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7646934460887949, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=100):
Best accuracy: 0.7741014799154333, best hyperparameter: {'C': 0.2, 'kernel': 'poly'}
Accuracy on test set: 0.717948717948718

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7623150105708246, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.764693446088795, best hyperparameter: {'max_depth': 5, 'n_estimators': 80}
Accuracy on test set: 0.6923076923076923

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7830866807610993, best hyperparameter: {'max_depth': 5, 'n_estimators': 80}
Accuracy on test set: 0.7051282051282052

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 5 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7739957716701902, best hyperparameter: {'C': 5, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7830338266384776, best hyperparameter: {'alpha': 5, 'max_iter': None}
Accuracy on test set: 0.8461538461538461

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7649577167019027, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.7948717948717948

Result of KNeighborsClassifier():
Best accuracy: 0.7650634249471459, best hyperparameter: {'n_neighbors': 9, 'weights': 'uniform'}
Accuracy on test set: 0.7948717948717948

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7739429175475687, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8205128205128205

Result of SVC(random_state=100):
Best accuracy: 0.7852536997885835, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.8076923076923077

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7738372093023255, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.77838266384778, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.8333333333333334

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7762156448202958, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.8076923076923077

Step Forward Feature Selection with AdaBoostClassifier(random_state=100) to select 5 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7897463002114165, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7852008456659618, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7347780126849894, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.7690803382663848, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.7435897435897436

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7876321353065538, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8333333333333334

Result of SVC(random_state=100):
Best accuracy: 0.7943974630021142, best hyperparameter: {'C': 5, 'kernel': 'linear'}
Accuracy on test set: 0.8076923076923077

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7943974630021142, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 100}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7623150105708246, best hyperparameter: {'max_depth': 5, 'n_estimators': 10}
Accuracy on test set: 0.7307692307692307

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7805496828752642, best hyperparameter: {'max_depth': 5, 'n_estimators': 80}
Accuracy on test set: 0.8076923076923077

Step Forward Feature Selection with LogisticRegression(random_state=100) to select 6 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7921247357293868, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7944503171247357, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.750845665961945, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6923076923076923

Result of KNeighborsClassifier():
Best accuracy: 0.7689746300211417, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.7564102564102564

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.785306553911205, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8333333333333334

Result of SVC(random_state=100):
Best accuracy: 0.8034883720930232, best hyperparameter: {'C': 1, 'kernel': 'poly'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.789799154334038, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.780813953488372, best hyperparameter: {'max_depth': 5, 'n_estimators': 30}
Accuracy on test set: 0.782051282051282

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.789799154334038, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.7948717948717948

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 6 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7990486257928119, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8717948717948718

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7943446088794925, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.8717948717948718

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7624735729386892, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.769397463002114, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.8461538461538461

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7966701902748413, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8717948717948718

Result of SVC(random_state=100):
Best accuracy: 0.8104651162790697, best hyperparameter: {'C': 1, 'kernel': 'rbf'}
Accuracy on test set: 0.8589743589743589

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7921775898520084, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7989429175475686, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.8461538461538461

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.8080866807610994, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.8461538461538461

Step Forward Feature Selection with AdaBoostClassifier(random_state=100) to select 6 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7874735729386891, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7852008456659618, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7233615221987316, best hyperparameter: {'class_weight': None, 'max_depth': None}
Accuracy on test set: 0.717948717948718

Result of KNeighborsClassifier():
Best accuracy: 0.7690803382663848, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.7435897435897436

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7876321353065538, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8333333333333334

Result of SVC(random_state=100):
Best accuracy: 0.7989957716701902, best hyperparameter: {'C': 5, 'kernel': 'linear'}
Accuracy on test set: 0.8205128205128205

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7921247357293868, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 100}
Accuracy on test set: 0.8205128205128205

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7669133192389006, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.8205128205128205

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7691331923890063, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.782051282051282

Step Forward Feature Selection with LogisticRegression(random_state=100) to select 7 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8058668076109937, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.8333333333333334

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7943974630021142, best hyperparameter: {'alpha': 5, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7508985200845666, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.717948717948718

Result of KNeighborsClassifier():
Best accuracy: 0.7670190274841436, best hyperparameter: {'n_neighbors': 5, 'weights': 'uniform'}
Accuracy on test set: 0.7435897435897436

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7899048625792812, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8461538461538461

Result of SVC(random_state=100):
Best accuracy: 0.796828752642706, best hyperparameter: {'C': 0.2, 'kernel': 'rbf'}
Accuracy on test set: 0.8076923076923077

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7921775898520084, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7874735729386891, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.8076923076923077

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7853594080338265, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.7948717948717948

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 7 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.796723044397463, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8461538461538461

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7874735729386891, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.8717948717948718

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7529598308668077, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.7692307692307693

Result of KNeighborsClassifier():
Best accuracy: 0.7852008456659618, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.7948717948717948

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7898520084566595, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8589743589743589

Result of SVC(random_state=100):
Best accuracy: 0.794291754756871, best hyperparameter: {'C': 0.2, 'kernel': 'rbf'}
Accuracy on test set: 0.8461538461538461

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7944503171247357, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7944503171247357, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.8076923076923077

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.8150634249471459, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.8205128205128205

Step Forward Feature Selection with AdaBoostClassifier(random_state=100) to select 7 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7807082452431289, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7944503171247357, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.720983086680761, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.7577167019027485, best hyperparameter: {'n_neighbors': 9, 'weights': 'uniform'}
Accuracy on test set: 0.7307692307692307

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7854122621564482, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8205128205128205

Result of SVC(random_state=100):
Best accuracy: 0.7922832980972515, best hyperparameter: {'C': 10, 'kernel': 'linear'}
Accuracy on test set: 0.8205128205128205

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7876849894291753, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.8076923076923077

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7596723044397463, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.717948717948718

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7804968287526427, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.7692307692307693

Step Forward Feature Selection with LogisticRegression(random_state=100) to select 8 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8171775898520085, best hyperparameter: {'C': 5, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.8035412262156448, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.782051282051282

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7418076109936576, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.7693446088794925, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.8205128205128205

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.794397463002114, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8333333333333334

Result of SVC(random_state=100):
Best accuracy: 0.8058668076109937, best hyperparameter: {'C': 1, 'kernel': 'poly'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.8011099365750528, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 100}
Accuracy on test set: 0.8461538461538461

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7855708245243129, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.782051282051282

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7921247357293868, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.7692307692307693

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 8 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7967758985200846, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.8589743589743589

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7991543340380549, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8461538461538461

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7624735729386891, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.7875264270613107, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.8205128205128205

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7783826638477802, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8333333333333334

Result of SVC(random_state=100):
Best accuracy: 0.7987315010570825, best hyperparameter: {'C': 5, 'kernel': 'rbf'}
Accuracy on test set: 0.8076923076923077

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7921775898520084, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.80338266384778, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.8205128205128205

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7967230443974629, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.8076923076923077

Step Forward Feature Selection with AdaBoostClassifier(random_state=100) to select 8 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7945031712473571, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.8333333333333334

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7944503171247357, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.720983086680761, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.7623150105708246, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.717948717948718

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.787737843551797, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8205128205128205

Result of SVC(random_state=100):
Best accuracy: 0.7945560253699788, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.8205128205128205

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7967758985200846, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 50}
Accuracy on test set: 0.8461538461538461

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7714587737843553, best hyperparameter: {'max_depth': 5, 'n_estimators': 80}
Accuracy on test set: 0.7948717948717948

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7714587737843553, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.782051282051282

Step Forward Feature Selection with LogisticRegression(random_state=100) to select 9 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8218287526427062, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.805813953488372, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7440274841437633, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.7554968287526427, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.7307692307692307

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7921247357293868, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8333333333333334

Result of SVC(random_state=100):
Best accuracy: 0.8126321353065539, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7948717948717948

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.8056553911205073, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 80}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.789799154334038, best hyperparameter: {'max_depth': 5, 'n_estimators': 80}
Accuracy on test set: 0.8205128205128205

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7899048625792812, best hyperparameter: {'max_depth': 5, 'n_estimators': 80}
Accuracy on test set: 0.8205128205128205

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 9 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7876321353065538, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.8461538461538461

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.796828752642706, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8333333333333334

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7440274841437633, best hyperparameter: {'class_weight': None, 'max_depth': None}
Accuracy on test set: 0.7692307692307693

Result of KNeighborsClassifier():
Best accuracy: 0.794397463002114, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.8076923076923077

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7829281183932346, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8589743589743589

Result of SVC(random_state=100):
Best accuracy: 0.8009513742071883, best hyperparameter: {'C': 1, 'kernel': 'poly'}
Accuracy on test set: 0.7948717948717948

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7899577167019027, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8205128205128205

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.8033298097251584, best hyperparameter: {'max_depth': 10, 'n_estimators': 30}
Accuracy on test set: 0.8461538461538461

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.8149577167019026, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.8717948717948718

Step Forward Feature Selection with AdaBoostClassifier(random_state=100) to select 9 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.796723044397463, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7966701902748413, best hyperparameter: {'alpha': 1, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7300739957716702, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.753171247357294, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6923076923076923

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7922832980972515, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8205128205128205

Result of SVC(random_state=100):
Best accuracy: 0.7945031712473571, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.8333333333333334

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7945560253699788, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.769291754756871, best hyperparameter: {'max_depth': 5, 'n_estimators': 10}
Accuracy on test set: 0.7307692307692307

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7782769556025371, best hyperparameter: {'max_depth': 5, 'n_estimators': 10}
Accuracy on test set: 0.717948717948718

Step Forward Feature Selection with LogisticRegression(random_state=100) to select 10 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8196617336152221, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.805813953488372, best hyperparameter: {'alpha': 5, 'max_iter': None}
Accuracy on test set: 0.8333333333333334

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7417019027484144, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.7625264270613108, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.7948717948717948

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8058668076109937, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8461538461538461

Result of SVC(random_state=100):
Best accuracy: 0.8126321353065539, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.8076923076923077

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.8057082452431288, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 50}
Accuracy on test set: 0.8461538461538461

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7876321353065538, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.782051282051282

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7943974630021142, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.782051282051282

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 10 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7876849894291753, best hyperparameter: {'C': 5, 'max_iter': 50}
Accuracy on test set: 0.8333333333333334

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7899577167019027, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8333333333333334

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7439217758985202, best hyperparameter: {'class_weight': None, 'max_depth': None}
Accuracy on test set: 0.782051282051282

Result of KNeighborsClassifier():
Best accuracy: 0.7758456659619452, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.782051282051282

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7784355179704017, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8589743589743589

Result of SVC(random_state=100):
Best accuracy: 0.7966701902748413, best hyperparameter: {'C': 0.2, 'kernel': 'rbf'}
Accuracy on test set: 0.8589743589743589

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7900634249471458, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.8076923076923077

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7989429175475686, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.8333333333333334

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.8059725158562367, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.8205128205128205

Step Forward Feature Selection with AdaBoostClassifier(random_state=100) to select 10 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.796723044397463, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7966701902748415, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7232558139534884, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.7443446088794925, best hyperparameter: {'n_neighbors': 5, 'weights': 'uniform'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7876849894291754, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8205128205128205

Result of SVC(random_state=100):
Best accuracy: 0.7900105708245244, best hyperparameter: {'C': 50, 'kernel': 'linear'}
Accuracy on test set: 0.8205128205128205

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7967758985200846, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.769291754756871, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.7948717948717948

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7874207188160677, best hyperparameter: {'max_depth': 5, 'n_estimators': 80}
Accuracy on test set: 0.7692307692307693

Step Forward Feature Selection with LogisticRegression(random_state=100) to select 11 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8242071881606765, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.812737843551797, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.8461538461538461

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7439746300211417, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.7419133192389007, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.782051282051282

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.801321353065539, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8461538461538461

Result of SVC(random_state=100):
Best accuracy: 0.812737843551797, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.8076923076923077

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.8103594080338266, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 80}
Accuracy on test set: 0.8589743589743589

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7761627906976744, best hyperparameter: {'max_depth': 5, 'n_estimators': 80}
Accuracy on test set: 0.7948717948717948

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.8035412262156448, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.7948717948717948

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 11 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7944503171247357, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.8461538461538461

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.79223044397463, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8461538461538461

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.757663847780127, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.7564102564102564

Result of KNeighborsClassifier():
Best accuracy: 0.7622093023255815, best hyperparameter: {'n_neighbors': 3, 'weights': 'distance'}
Accuracy on test set: 0.7692307692307693

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.794291754756871, best hyperparameter: {'solver': 'lsqr'}
Accuracy on test set: 0.8333333333333334

Result of SVC(random_state=100):
Best accuracy: 0.8033298097251584, best hyperparameter: {'C': 50, 'kernel': 'rbf'}
Accuracy on test set: 0.8205128205128205

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7988900634249472, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.805708245243129, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.8205128205128205

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.8034883720930232, best hyperparameter: {'max_depth': None, 'n_estimators': 30}
Accuracy on test set: 0.8333333333333334

Step Forward Feature Selection with AdaBoostClassifier(random_state=100) to select 11 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7989429175475686, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.8461538461538461

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.801321353065539, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7210887949260043, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.7441331923890064, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6410256410256411

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7876849894291755, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8076923076923077

Result of SVC(random_state=100):
Best accuracy: 0.7899048625792812, best hyperparameter: {'C': 5, 'kernel': 'linear'}
Accuracy on test set: 0.8333333333333334

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.796723044397463, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7715116279069767, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.7692307692307693

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.77838266384778, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.717948717948718

Step Forward Feature Selection with LogisticRegression(random_state=100) to select 12 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8264799154334037, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.8081395348837208, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7556553911205073, best hyperparameter: {'class_weight': None, 'max_depth': None}
Accuracy on test set: 0.7948717948717948

Result of KNeighborsClassifier():
Best accuracy: 0.7350951374207189, best hyperparameter: {'n_neighbors': 5, 'weights': 'uniform'}
Accuracy on test set: 0.7435897435897436

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8035940803382664, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8461538461538461

Result of SVC(random_state=100):
Best accuracy: 0.8150105708245243, best hyperparameter: {'C': 1, 'kernel': 'linear'}
Accuracy on test set: 0.7948717948717948

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.805813953488372, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8076923076923077

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7807610993657506, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.782051282051282

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7922832980972515, best hyperparameter: {'max_depth': 5, 'n_estimators': 80}
Accuracy on test set: 0.8205128205128205

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 12 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7988900634249472, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.8461538461538461

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7899048625792812, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8333333333333334

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7510042283298096, best hyperparameter: {'class_weight': None, 'max_depth': None}
Accuracy on test set: 0.7051282051282052

Result of KNeighborsClassifier():
Best accuracy: 0.7394820295983088, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.7948717948717948

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.789799154334038, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8333333333333334

Result of SVC(random_state=100):
Best accuracy: 0.7920718816067653, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.8205128205128205

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7965644820295982, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7919133192389006, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.8205128205128205

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.810306553911205, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.7948717948717948

Step Forward Feature Selection with AdaBoostClassifier(random_state=100) to select 12 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7989429175475686, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.8461538461538461

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.8035940803382664, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.720877378435518, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 10}
Accuracy on test set: 0.717948717948718

Result of KNeighborsClassifier():
Best accuracy: 0.7534355179704016, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.6282051282051282

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7854122621564482, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8205128205128205

Result of SVC(random_state=100):
Best accuracy: 0.79223044397463, best hyperparameter: {'C': 50, 'kernel': 'linear'}
Accuracy on test set: 0.8205128205128205

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.796723044397463, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7623678646934462, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.7307692307692307

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7875264270613107, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.7692307692307693

Step Forward Feature Selection with LogisticRegression(random_state=100) to select 13 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8310253699788583, best hyperparameter: {'C': 5, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.8126849894291756, best hyperparameter: {'alpha': 5, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7508456659619451, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7564102564102564

Result of KNeighborsClassifier():
Best accuracy: 0.737262156448203, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.782051282051282

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8058668076109937, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8333333333333334

Result of SVC(random_state=100):
Best accuracy: 0.8128964059196617, best hyperparameter: {'C': 5, 'kernel': 'linear'}
Accuracy on test set: 0.8076923076923077

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.8080866807610994, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8076923076923077

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7830338266384776, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.8205128205128205

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7760570824524314, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.8076923076923077

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 13 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8080338266384779, best hyperparameter: {'C': 5, 'max_iter': 50}
Accuracy on test set: 0.8333333333333334

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.796723044397463, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8461538461538461

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7463002114164906, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7564102564102564

Result of KNeighborsClassifier():
Best accuracy: 0.748678646934461, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.7948717948717948

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7921247357293868, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8205128205128205

Result of SVC(random_state=100):
Best accuracy: 0.7896934460887948, best hyperparameter: {'C': 1, 'kernel': 'poly'}
Accuracy on test set: 0.7948717948717948

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7988900634249472, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8205128205128205

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.8035940803382664, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.8461538461538461

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.8105179704016914, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.8205128205128205

Step Forward Feature Selection with AdaBoostClassifier(random_state=100) to select 13 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7989957716701902, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7967758985200846, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7121035940803383, best hyperparameter: {'class_weight': None, 'max_depth': None}
Accuracy on test set: 0.6794871794871795

Result of KNeighborsClassifier():
Best accuracy: 0.7510042283298096, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6410256410256411

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.787737843551797, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8076923076923077

Result of SVC(random_state=100):
Best accuracy: 0.7875792811839324, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7948717948717948

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7943974630021142, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7690274841437633, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.7435897435897436

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7758985200845666, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7307692307692307

Step Forward Feature Selection with LogisticRegression(random_state=100) to select 14 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8310253699788583, best hyperparameter: {'C': 5, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.8149577167019026, best hyperparameter: {'alpha': 0.5, 'max_iter': None}
Accuracy on test set: 0.8333333333333334

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7462473572938689, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.7327167019027484, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.7692307692307693

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8081395348837208, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8205128205128205

Result of SVC(random_state=100):
Best accuracy: 0.8128964059196617, best hyperparameter: {'C': 5, 'kernel': 'linear'}
Accuracy on test set: 0.8076923076923077

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.805813953488372, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8076923076923077

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7716701902748413, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.8076923076923077

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7785412262156447, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.8589743589743589

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 14 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8034883720930232, best hyperparameter: {'C': 5, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.796723044397463, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8333333333333334

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7463002114164905, best hyperparameter: {'class_weight': None, 'max_depth': None}
Accuracy on test set: 0.7564102564102564

Result of KNeighborsClassifier():
Best accuracy: 0.7419133192389007, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.8205128205128205

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7921247357293868, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8076923076923077

Result of SVC(random_state=100):
Best accuracy: 0.789693446088795, best hyperparameter: {'C': 1, 'kernel': 'poly'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7988900634249472, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8205128205128205

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7965644820295982, best hyperparameter: {'max_depth': None, 'n_estimators': 30}
Accuracy on test set: 0.782051282051282

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.8012684989429175, best hyperparameter: {'max_depth': 5, 'n_estimators': 30}
Accuracy on test set: 0.8076923076923077

Step Forward Feature Selection with AdaBoostClassifier(random_state=100) to select 14 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8012684989429175, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.8126849894291753, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7189746300211418, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.6923076923076923

Result of KNeighborsClassifier():
Best accuracy: 0.7463530655391122, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7876321353065538, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=100):
Best accuracy: 0.7853594080338266, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.8076923076923077

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7989957716701902, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8205128205128205

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7669661733615223, best hyperparameter: {'max_depth': 10, 'n_estimators': 30}
Accuracy on test set: 0.7307692307692307

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7783298097251585, best hyperparameter: {'max_depth': 5, 'n_estimators': 30}
Accuracy on test set: 0.717948717948718

Step Forward Feature Selection with LogisticRegression(random_state=100) to select 15 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.828752642706131, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.8126849894291753, best hyperparameter: {'alpha': 5, 'max_iter': None}
Accuracy on test set: 0.8333333333333334

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7464587737843552, best hyperparameter: {'class_weight': None, 'max_depth': None}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.7304439746300212, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.6666666666666666

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8081923890063425, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8205128205128205

Result of SVC(random_state=100):
Best accuracy: 0.8151691331923889, best hyperparameter: {'C': 10, 'kernel': 'linear'}
Accuracy on test set: 0.8205128205128205

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.8079809725158562, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.8205128205128205

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7761627906976744, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.8333333333333334

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7810253699788583, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.8076923076923077

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 15 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7989957716701902, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7943974630021142, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7463530655391122, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.717948717948718

Result of KNeighborsClassifier():
Best accuracy: 0.7463530655391122, best hyperparameter: {'n_neighbors': 9, 'weights': 'uniform'}
Accuracy on test set: 0.7948717948717948

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7853594080338265, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8205128205128205

Result of SVC(random_state=100):
Best accuracy: 0.7829281183932346, best hyperparameter: {'C': 50, 'kernel': 'linear'}
Accuracy on test set: 0.8333333333333334

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7988900634249472, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8461538461538461

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7919661733615222, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.8205128205128205

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.8080866807610994, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.8076923076923077

Step Forward Feature Selection with AdaBoostClassifier(random_state=100) to select 15 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.796723044397463, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.8104651162790697, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7051797040169134, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7692307692307693

Result of KNeighborsClassifier():
Best accuracy: 0.7396405919661733, best hyperparameter: {'n_neighbors': 9, 'weights': 'uniform'}
Accuracy on test set: 0.6410256410256411

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7854651162790697, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=100):
Best accuracy: 0.7807610993657506, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.8076923076923077

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.8012156448202961, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.7051282051282052

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7669133192389006, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.7692307692307693

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7829281183932346, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.7435897435897436

Step Forward Feature Selection with LogisticRegression(random_state=100) to select 16 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8310253699788583, best hyperparameter: {'C': 5, 'max_iter': 50}
Accuracy on test set: 0.7435897435897436

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.8081923890063424, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7416490486257928, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7564102564102564

Result of KNeighborsClassifier():
Best accuracy: 0.741860465116279, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.7051282051282052

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8082452431289641, best hyperparameter: {'solver': 'lsqr'}
Accuracy on test set: 0.8205128205128205

Result of SVC(random_state=100):
Best accuracy: 0.8150634249471459, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.8126849894291753, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7692307692307693

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.773890063424947, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7948717948717948

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7921247357293868, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.7692307692307693

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 16 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7989429175475686, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.79223044397463, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8333333333333334

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7532241014799155, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.717948717948718

Result of KNeighborsClassifier():
Best accuracy: 0.7510570824524312, best hyperparameter: {'n_neighbors': 9, 'weights': 'uniform'}
Accuracy on test set: 0.7692307692307693

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7876321353065538, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8205128205128205

Result of SVC(random_state=100):
Best accuracy: 0.7805496828752643, best hyperparameter: {'C': 1, 'kernel': 'poly'}
Accuracy on test set: 0.7307692307692307

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7966173361522199, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8461538461538461

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7919133192389005, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.782051282051282

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.8058668076109937, best hyperparameter: {'max_depth': 5, 'n_estimators': 30}
Accuracy on test set: 0.8076923076923077

Step Forward Feature Selection with AdaBoostClassifier(random_state=100) to select 16 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8035412262156447, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.8059196617336152, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7006342494714588, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.7259513742071881, best hyperparameter: {'n_neighbors': 9, 'weights': 'uniform'}
Accuracy on test set: 0.6282051282051282

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7900634249471459, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=100):
Best accuracy: 0.7876321353065538, best hyperparameter: {'C': 1, 'kernel': 'linear'}
Accuracy on test set: 0.8205128205128205

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.8080866807610994, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7739429175475687, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.7692307692307693

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.773890063424947, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.717948717948718

Step Forward Feature Selection with LogisticRegression(random_state=100) to select 17 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.828752642706131, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.8081395348837208, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7439746300211415, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.782051282051282

Result of KNeighborsClassifier():
Best accuracy: 0.7646405919661733, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6538461538461539

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8081395348837208, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8461538461538461

Result of SVC(random_state=100):
Best accuracy: 0.8128435517970403, best hyperparameter: {'C': 1, 'kernel': 'linear'}
Accuracy on test set: 0.7948717948717948

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.8081395348837208, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7692307692307693

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7806553911205073, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.8076923076923077

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7806553911205073, best hyperparameter: {'max_depth': 5, 'n_estimators': 30}
Accuracy on test set: 0.782051282051282

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 17 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8011627906976744, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7921247357293868, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7486257928118395, best hyperparameter: {'class_weight': None, 'max_depth': None}
Accuracy on test set: 0.7051282051282052

Result of KNeighborsClassifier():
Best accuracy: 0.7510042283298096, best hyperparameter: {'n_neighbors': 9, 'weights': 'uniform'}
Accuracy on test set: 0.7435897435897436

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7853594080338266, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8076923076923077

Result of SVC(random_state=100):
Best accuracy: 0.7806553911205073, best hyperparameter: {'C': 50, 'kernel': 'linear'}
Accuracy on test set: 0.7948717948717948

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7988372093023255, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.807875264270613, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.8205128205128205

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.8035412262156447, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.782051282051282

Step Forward Feature Selection with AdaBoostClassifier(random_state=100) to select 17 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8036469344608879, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.8105179704016912, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7051268498942919, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.7260042283298096, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6025641025641025

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7876849894291755, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=100):
Best accuracy: 0.7875792811839324, best hyperparameter: {'C': 1, 'kernel': 'linear'}
Accuracy on test set: 0.8205128205128205

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.8081923890063424, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7692389006342493, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.7948717948717948

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7804968287526427, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7692307692307693

Step Forward Feature Selection with LogisticRegression(random_state=100) to select 18 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8288054968287526, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.8150634249471459, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7623150105708245, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.717948717948718

Result of KNeighborsClassifier():
Best accuracy: 0.7464059196617335, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6923076923076923

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8082452431289641, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8205128205128205

Result of SVC(random_state=100):
Best accuracy: 0.8242600422832981, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.7948717948717948

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.805813953488372, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7948717948717948

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7805496828752643, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.8461538461538461

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7989957716701902, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.782051282051282

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 18 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7989429175475686, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7990486257928119, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7393763213530656, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7564102564102564

Result of KNeighborsClassifier():
Best accuracy: 0.7532769556025369, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.7435897435897436

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7945031712473571, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8076923076923077

Result of SVC(random_state=100):
Best accuracy: 0.7851479915433404, best hyperparameter: {'C': 50, 'kernel': 'linear'}
Accuracy on test set: 0.8076923076923077

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7875264270613107, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.8104122621564482, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.8076923076923077

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7897463002114165, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.7692307692307693

Step Forward Feature Selection with AdaBoostClassifier(random_state=100) to select 18 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8036469344608879, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.8105179704016912, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7074524312896406, best hyperparameter: {'class_weight': None, 'max_depth': None}
Accuracy on test set: 0.7051282051282052

Result of KNeighborsClassifier():
Best accuracy: 0.7144291754756871, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5769230769230769

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7854122621564482, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=100):
Best accuracy: 0.7875792811839324, best hyperparameter: {'C': 1, 'kernel': 'linear'}
Accuracy on test set: 0.8205128205128205

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.8081923890063424, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7829281183932346, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.782051282051282

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7738372093023255, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.7307692307692307

Step Forward Feature Selection with LogisticRegression(random_state=100) to select 19 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8310253699788582, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.8150105708245242, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7416490486257928, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.6923076923076923

Result of KNeighborsClassifier():
Best accuracy: 0.7443446088794926, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6794871794871795

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8036997885835095, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8205128205128205

Result of SVC(random_state=100):
Best accuracy: 0.8151162790697674, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.805813953488372, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.782051282051282

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7669661733615223, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7948717948717948

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7807610993657506, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.782051282051282

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 19 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7943974630021142, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.789799154334038, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7485200845665962, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.717948717948718

Result of KNeighborsClassifier():
Best accuracy: 0.748784355179704, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.717948717948718

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.785306553911205, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8076923076923077

Result of SVC(random_state=100):
Best accuracy: 0.776215644820296, best hyperparameter: {'C': 5, 'kernel': 'poly'}
Accuracy on test set: 0.7435897435897436

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7806025369978858, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.785306553911205, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7948717948717948

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.8012684989429175, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.8205128205128205

Step Forward Feature Selection with AdaBoostClassifier(random_state=100) to select 19 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7969344608879492, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.8104651162790697, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7189217758985201, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.717948717948718

Result of KNeighborsClassifier():
Best accuracy: 0.7052854122621565, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5641025641025641

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7809196617336152, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8076923076923077

Result of SVC(random_state=100):
Best accuracy: 0.7876321353065538, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.8205128205128205

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.801321353065539, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7738372093023255, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.7435897435897436

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7829281183932346, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.7692307692307693

Step Forward Feature Selection with LogisticRegression(random_state=100) to select 20 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8309725158562367, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.8218816067653277, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7393234672304441, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.7466173361522199, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.6666666666666666

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8150105708245243, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8205128205128205

Result of SVC(random_state=100):
Best accuracy: 0.815169133192389, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.7948717948717948

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.8104651162790697, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8076923076923077

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7737315010570824, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.782051282051282

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7852536997885836, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.8205128205128205

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 20 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7966701902748413, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7898520084566595, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7348837209302326, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.744291754756871, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.717948717948718

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7830866807610993, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=100):
Best accuracy: 0.7761099365750528, best hyperparameter: {'C': 10, 'kernel': 'rbf'}
Accuracy on test set: 0.7307692307692307

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7806025369978858, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8461538461538461

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7966173361522199, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.7435897435897436

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7922832980972515, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.7692307692307693

Step Forward Feature Selection with AdaBoostClassifier(random_state=100) to select 20 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7968816067653277, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7989429175475687, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7141649048625793, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7564102564102564

Result of KNeighborsClassifier():
Best accuracy: 0.7051797040169134, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5512820512820513

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7831923890063425, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8205128205128205

Result of SVC(random_state=100):
Best accuracy: 0.7829809725158562, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.8461538461538461

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7967758985200846, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7714587737843551, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7435897435897436

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7691860465116279, best hyperparameter: {'max_depth': 20, 'n_estimators': 100}
Accuracy on test set: 0.7307692307692307

Step Backward Feature Selection with LogisticRegression(random_state=100) to select 60 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8150105708245242, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7899048625792812, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.782051282051282

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7215116279069766, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.6506871035940803, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6794871794871795

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7738372093023256, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=100):
Best accuracy: 0.7762684989429175, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7785412262156447, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8205128205128205

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7532241014799154, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7564102564102564

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7715644820295984, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.8205128205128205

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 60 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7352536997885835, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7373150105708246, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.6732029598308669, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.6410256410256411

Result of KNeighborsClassifier():
Best accuracy: 0.6325052854122621, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7304968287526428, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=100):
Best accuracy: 0.7329281183932347, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7948717948717948

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7237843551797041, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7418076109936577, best hyperparameter: {'max_depth': None, 'n_estimators': 30}
Accuracy on test set: 0.7307692307692307

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.739693446088795, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.7307692307692307

Step Backward Feature Selection with AdaBoostClassifier(random_state=100) to select 60 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7761627906976744, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7830338266384776, best hyperparameter: {'alpha': 5, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7304439746300212, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.6644291754756871, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7761099365750528, best hyperparameter: {'solver': 'lsqr'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=100):
Best accuracy: 0.7806553911205073, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7944503171247357, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7553911205073995, best hyperparameter: {'max_depth': None, 'n_estimators': 30}
Accuracy on test set: 0.717948717948718

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7643763213530657, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.7564102564102564

Step Backward Feature Selection with LogisticRegression(random_state=100) to select 61 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.812737843551797, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7943974630021142, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7169661733615221, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.6576638477801269, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6538461538461539

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7670190274841437, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=100):
Best accuracy: 0.7601479915433405, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.8076923076923077

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.780813953488372, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8205128205128205

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7600951374207188, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.782051282051282

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.753171247357294, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.8076923076923077

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 61 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7260570824524313, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7350422832980972, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.6848837209302326, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.6210359408033828, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7259513742071882, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=100):
Best accuracy: 0.7330866807610994, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7948717948717948

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7237315010570824, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7327695560253701, best hyperparameter: {'max_depth': None, 'n_estimators': 30}
Accuracy on test set: 0.717948717948718

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7443446088794925, best hyperparameter: {'max_depth': 20, 'n_estimators': 50}
Accuracy on test set: 0.717948717948718

Step Backward Feature Selection with AdaBoostClassifier(random_state=100) to select 61 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7806025369978856, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.8333333333333334

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.785306553911205, best hyperparameter: {'alpha': 1, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7396405919661734, best hyperparameter: {'class_weight': None, 'max_depth': None}
Accuracy on test set: 0.6666666666666666

Result of KNeighborsClassifier():
Best accuracy: 0.6414376321353066, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6538461538461539

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7715644820295984, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=100):
Best accuracy: 0.7829281183932346, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7944503171247357, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7485729386892177, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.782051282051282

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7575581395348838, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7948717948717948

Step Backward Feature Selection with LogisticRegression(random_state=100) to select 62 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.812737843551797, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7921247357293868, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7305496828752641, best hyperparameter: {'class_weight': None, 'max_depth': None}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.6599365750528542, best hyperparameter: {'n_neighbors': 5, 'weights': 'uniform'}
Accuracy on test set: 0.6282051282051282

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7738372093023256, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=100):
Best accuracy: 0.7579281183932347, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.8076923076923077

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7830866807610993, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7417547568710359, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.8076923076923077

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7645348837209303, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.7948717948717948

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 62 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7283298097251585, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7350422832980972, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.682663847780127, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.6302325581395348, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7191331923890064, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=100):
Best accuracy: 0.7330866807610994, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7948717948717948

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7237315010570824, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.725845665961945, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7307692307692307

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7352536997885835, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.7435897435897436

Step Backward Feature Selection with AdaBoostClassifier(random_state=100) to select 62 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7828752642706129, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.8333333333333334

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7807610993657506, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7327167019027484, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.6323467230443975, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7715644820295984, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=100):
Best accuracy: 0.7737315010570824, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7944503171247357, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7441331923890063, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.7692307692307693

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7554439746300211, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.7435897435897436

Step Backward Feature Selection with LogisticRegression(random_state=100) to select 63 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.812737843551797, best hyperparameter: {'C': 1, 'max_iter': 100}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7921247357293868, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8333333333333334

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.728276955602537, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.6599365750528541, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6666666666666666

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7670718816067653, best hyperparameter: {'solver': 'lsqr'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=100):
Best accuracy: 0.7534355179704016, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7716701902748413, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.744291754756871, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.7307692307692307

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7512684989429175, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7948717948717948

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 63 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7445031712473572, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7465116279069767, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.6894291754756872, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.6210887949260042, best hyperparameter: {'n_neighbors': 9, 'weights': 'uniform'}
Accuracy on test set: 0.5512820512820513

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7374207188160676, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=100):
Best accuracy: 0.7511627906976743, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.723890063424947, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 50}
Accuracy on test set: 0.8076923076923077

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7259513742071882, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.7564102564102564

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7258985200845666, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.7692307692307693

Step Backward Feature Selection with AdaBoostClassifier(random_state=100) to select 63 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7828224101479916, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.8333333333333334

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7852536997885835, best hyperparameter: {'alpha': 5, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7258456659619451, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.6437632135306555, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6282051282051282

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7669661733615223, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=100):
Best accuracy: 0.7691331923890063, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7944503171247357, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7556553911205073, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.7564102564102564

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7530655391120508, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.7564102564102564

Step Backward Feature Selection with LogisticRegression(random_state=100) to select 64 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8104651162790697, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7898520084566595, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7168076109936575, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.6598837209302325, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6666666666666666

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7625264270613108, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=100):
Best accuracy: 0.755708245243129, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7693974630021142, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7624735729386891, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.782051282051282

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7784883720930231, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.8333333333333334

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 64 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7421775898520083, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7419661733615223, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.6873150105708246, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.6368921775898521, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.728276955602537, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=100):
Best accuracy: 0.7488372093023256, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7261627906976743, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 50}
Accuracy on test set: 0.8205128205128205

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7439217758985202, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.782051282051282

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7372621564482029, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7435897435897436

Step Backward Feature Selection with AdaBoostClassifier(random_state=100) to select 64 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7782769556025371, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.8333333333333334

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7852536997885835, best hyperparameter: {'alpha': 5, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7280655391120507, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.6529598308668076, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6025641025641025

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7646934460887949, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=100):
Best accuracy: 0.7714059196617338, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7948717948717948

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7944503171247357, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7486786469344608, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.782051282051282

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7782241014799155, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.8076923076923077

Step Backward Feature Selection with LogisticRegression(random_state=100) to select 65 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8081923890063425, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7898520084566595, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7168076109936575, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.659830866807611, best hyperparameter: {'n_neighbors': 5, 'weights': 'uniform'}
Accuracy on test set: 0.6410256410256411

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7625264270613108, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=100):
Best accuracy: 0.7534883720930232, best hyperparameter: {'C': 5, 'kernel': 'rbf'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7693446088794926, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7578752642706131, best hyperparameter: {'max_depth': 5, 'n_estimators': 80}
Accuracy on test set: 0.7692307692307693

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7670190274841439, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.7435897435897436

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 65 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7488900634249471, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7442389006342495, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.782051282051282

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.6918076109936575, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.6187632135306554, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.5897435897435898

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7350951374207189, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=100):
Best accuracy: 0.7466173361522199, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.723784355179704, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7372093023255814, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.7564102564102564

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7420190274841437, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.7948717948717948

Step Backward Feature Selection with AdaBoostClassifier(random_state=100) to select 65 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7783298097251585, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.8333333333333334

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7852536997885835, best hyperparameter: {'alpha': 5, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7396405919661734, best hyperparameter: {'class_weight': None, 'max_depth': None}
Accuracy on test set: 0.6923076923076923

Result of KNeighborsClassifier():
Best accuracy: 0.6461416490486258, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.5897435897435898

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7624207188160678, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=100):
Best accuracy: 0.7714059196617338, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7944503171247357, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7532241014799155, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.7307692307692307

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7577167019027484, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.7692307692307693

Step Backward Feature Selection with LogisticRegression(random_state=100) to select 66 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8081395348837208, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.789799154334038, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7168076109936575, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.6600422832980972, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.6025641025641025

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7648520084566597, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=100):
Best accuracy: 0.7533298097251586, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7670190274841437, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8205128205128205

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7463530655391122, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7564102564102564

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.785306553911205, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.8205128205128205

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 66 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.744291754756871, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7557610993657505, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.6918076109936575, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.6325052854122623, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6025641025641025

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7351479915433404, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=100):
Best accuracy: 0.7443446088794926, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7261099365750529, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.8461538461538461

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7304439746300212, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.7692307692307693

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7304968287526428, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.7435897435897436

Step Backward Feature Selection with AdaBoostClassifier(random_state=100) to select 66 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7760570824524312, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.8461538461538461

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7875264270613107, best hyperparameter: {'alpha': 5, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7281183932346723, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.6392177589852008, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7624207188160678, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=100):
Best accuracy: 0.7691860465116279, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7948717948717948

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7944503171247357, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7598837209302326, best hyperparameter: {'max_depth': 10, 'n_estimators': 30}
Accuracy on test set: 0.7564102564102564

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7735200845665963, best hyperparameter: {'max_depth': 20, 'n_estimators': 50}
Accuracy on test set: 0.7564102564102564

Step Backward Feature Selection with LogisticRegression(random_state=100) to select 67 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8058668076109937, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7897991543340381, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7237315010570824, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.6554968287526427, best hyperparameter: {'n_neighbors': 5, 'weights': 'uniform'}
Accuracy on test set: 0.6282051282051282

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7671247357293869, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=100):
Best accuracy: 0.7512156448202958, best hyperparameter: {'C': 5, 'kernel': 'rbf'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7692917547568711, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8076923076923077

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7395877378435519, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.717948717948718

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7670190274841436, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.8333333333333334

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 67 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.744291754756871, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.741860465116279, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.6803911205073996, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.6323995771670191, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7237315010570825, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=100):
Best accuracy: 0.7373678646934461, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7237315010570824, best hyperparameter: {'estimator': None, 'n_estimators': 30}
Accuracy on test set: 0.7307692307692307

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7465644820295984, best hyperparameter: {'max_depth': None, 'n_estimators': 30}
Accuracy on test set: 0.7564102564102564

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7326638477801268, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.7948717948717948

Step Backward Feature Selection with AdaBoostClassifier(random_state=100) to select 67 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7760570824524312, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.8461538461538461

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7829809725158562, best hyperparameter: {'alpha': 1, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7235729386892178, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.6505813953488373, best hyperparameter: {'n_neighbors': 5, 'weights': 'uniform'}
Accuracy on test set: 0.5641025641025641

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7624735729386892, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=100):
Best accuracy: 0.7669133192389006, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7948717948717948

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7944503171247357, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7735729386892178, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.782051282051282

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7714587737843552, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7692307692307693

Step Backward Feature Selection with LogisticRegression(random_state=100) to select 68 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8035940803382664, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7875264270613107, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7168076109936575, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.6600951374207187, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6282051282051282

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7648520084566595, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=100):
Best accuracy: 0.7580338266384776, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7625264270613107, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.8076923076923077

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7623678646934462, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.7948717948717948

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7691860465116278, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.8461538461538461

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 68 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7580866807610993, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.7435897435897436

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.748890063424947, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7564102564102564

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.6827167019027484, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7564102564102564

Result of KNeighborsClassifier():
Best accuracy: 0.6234672304439747, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7328224101479915, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8076923076923077

Result of SVC(random_state=100):
Best accuracy: 0.7261099365750529, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.7435897435897436

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7237315010570825, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.7435897435897436

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7304439746300211, best hyperparameter: {'max_depth': 10, 'n_estimators': 30}
Accuracy on test set: 0.7564102564102564

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.753276955602537, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7692307692307693

Step Backward Feature Selection with AdaBoostClassifier(random_state=100) to select 68 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7783298097251585, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8461538461538461

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7852008456659619, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7349365750528543, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.6575581395348837, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7625792811839324, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=100):
Best accuracy: 0.7646405919661734, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7944503171247357, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7395348837209302, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.7435897435897436

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7509513742071882, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.782051282051282

Step Backward Feature Selection with LogisticRegression(random_state=100) to select 69 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.801321353065539, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7875264270613107, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7145877378435519, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.6599365750528542, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6282051282051282

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7671247357293869, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7435897435897436

Result of SVC(random_state=100):
Best accuracy: 0.7512684989429175, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7671247357293869, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8205128205128205

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7441860465116279, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7307692307692307

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7625264270613107, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.7564102564102564

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 69 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7512156448202959, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7486257928118392, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7564102564102564

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.6986786469344609, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7692307692307693

Result of KNeighborsClassifier():
Best accuracy: 0.6233615221987315, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7328752642706131, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=100):
Best accuracy: 0.7304439746300212, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.72838266384778, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.7435897435897436

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7282241014799153, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.7307692307692307

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7419133192389006, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.7948717948717948

Step Backward Feature Selection with AdaBoostClassifier(random_state=100) to select 69 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7784883720930231, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.8461538461538461

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7806553911205074, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7487315010570824, best hyperparameter: {'class_weight': None, 'max_depth': None}
Accuracy on test set: 0.6923076923076923

Result of KNeighborsClassifier():
Best accuracy: 0.655443974630021, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.5897435897435898

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7511627906976743, best hyperparameter: {'solver': 'lsqr'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=100):
Best accuracy: 0.7647463002114165, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7944503171247357, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7533826638477801, best hyperparameter: {'max_depth': None, 'n_estimators': 30}
Accuracy on test set: 0.7435897435897436

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.757875264270613, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.7435897435897436

Step Backward Feature Selection with LogisticRegression(random_state=100) to select 70 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.801321353065539, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7875264270613107, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7190274841437632, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.6736257928118394, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7693974630021142, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=100):
Best accuracy: 0.7510570824524312, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7671247357293869, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8076923076923077

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7440274841437632, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7692307692307693

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7556553911205073, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.7692307692307693

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 70 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7534883720930232, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7532241014799154, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7564102564102564

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.6850422832980972, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7692307692307693

Result of KNeighborsClassifier():
Best accuracy: 0.6188689217758985, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6025641025641025

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7236786469344609, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=100):
Best accuracy: 0.7306553911205074, best hyperparameter: {'C': 1, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.72838266384778, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.7435897435897436

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7236786469344609, best hyperparameter: {'max_depth': None, 'n_estimators': 30}
Accuracy on test set: 0.7692307692307693

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7189746300211417, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7564102564102564

Step Backward Feature Selection with AdaBoostClassifier(random_state=100) to select 70 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7784355179704017, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.8461538461538461

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7806553911205074, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7281183932346724, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.7051282051282052

Result of KNeighborsClassifier():
Best accuracy: 0.655443974630021, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.5897435897435898

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7488900634249471, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=100):
Best accuracy: 0.7625264270613108, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7944503171247357, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.741860465116279, best hyperparameter: {'max_depth': 5, 'n_estimators': 80}
Accuracy on test set: 0.7435897435897436

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7442389006342495, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.8076923076923077

Step Backward Feature Selection with LogisticRegression(random_state=100) to select 71 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7990486257928119, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7898520084566595, best hyperparameter: {'alpha': 5, 'max_iter': None}
Accuracy on test set: 0.7564102564102564

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7260042283298097, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.6417019027484143, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7602536997885835, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=100):
Best accuracy: 0.7488372093023256, best hyperparameter: {'C': 5, 'kernel': 'rbf'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7579809725158562, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8205128205128205

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7532769556025369, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.717948717948718

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7646405919661733, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.8333333333333334

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 71 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7466173361522198, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.7564102564102564

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7486786469344608, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7564102564102564

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.6918604651162791, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7564102564102564

Result of KNeighborsClassifier():
Best accuracy: 0.6370507399577168, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.5641025641025641

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7260570824524313, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=100):
Best accuracy: 0.7353594080338266, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7238372093023255, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.8076923076923077

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7484143763213531, best hyperparameter: {'max_depth': None, 'n_estimators': 30}
Accuracy on test set: 0.717948717948718

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7350951374207189, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.8333333333333334

Step Backward Feature Selection with AdaBoostClassifier(random_state=100) to select 71 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7829809725158563, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.8461538461538461

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7807082452431289, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7372093023255814, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.6923076923076923

Result of KNeighborsClassifier():
Best accuracy: 0.6577167019027483, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.5897435897435898

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7511627906976743, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=100):
Best accuracy: 0.7579281183932347, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7944503171247357, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7554968287526427, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.717948717948718

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7649048625792811, best hyperparameter: {'max_depth': 10, 'n_estimators': 30}
Accuracy on test set: 0.7692307692307693

Step Backward Feature Selection with LogisticRegression(random_state=100) to select 72 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7990486257928119, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7875792811839322, best hyperparameter: {'alpha': 5, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7168604651162791, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.6394291754756872, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7648520084566595, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=100):
Best accuracy: 0.7512156448202958, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7579809725158562, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8205128205128205

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.737367864693446, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.782051282051282

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7532769556025369, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.8205128205128205

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 72 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7420190274841437, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7443446088794926, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.782051282051282

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7077695560253701, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7564102564102564

Result of KNeighborsClassifier():
Best accuracy: 0.6254228329809726, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.5897435897435898

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7237315010570826, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8076923076923077

Result of SVC(random_state=100):
Best accuracy: 0.7330338266384778, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7215116279069768, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7948717948717948

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7465644820295982, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7948717948717948

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.721353065539112, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7692307692307693

Step Backward Feature Selection with AdaBoostClassifier(random_state=100) to select 72 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7830338266384776, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.8333333333333334

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7783298097251585, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7349894291754758, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.6622093023255814, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.6282051282051282

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7533298097251586, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=100):
Best accuracy: 0.7602536997885836, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7944503171247357, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7575581395348837, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7564102564102564

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7758985200845667, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.782051282051282

Step Backward Feature Selection with LogisticRegression(random_state=100) to select 73 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7990486257928119, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7875792811839322, best hyperparameter: {'alpha': 5, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7168604651162791, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.6440274841437632, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7693974630021142, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=100):
Best accuracy: 0.7489429175475687, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7625264270613107, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8076923076923077

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7441860465116278, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.7948717948717948

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.764799154334038, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.8076923076923077

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 73 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7488372093023256, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7443446088794926, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.7435897435897436

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7124207188160677, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7564102564102564

Result of KNeighborsClassifier():
Best accuracy: 0.6391120507399577, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.6025641025641025

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7305496828752642, best hyperparameter: {'solver': 'lsqr'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=100):
Best accuracy: 0.7443974630021143, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7215116279069768, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7948717948717948

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7464587737843551, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.7307692307692307

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7534355179704016, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.782051282051282

Step Backward Feature Selection with AdaBoostClassifier(random_state=100) to select 73 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7761099365750528, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.8333333333333334

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7737843551797041, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7326109936575054, best hyperparameter: {'class_weight': None, 'max_depth': None}
Accuracy on test set: 0.717948717948718

Result of KNeighborsClassifier():
Best accuracy: 0.6484672304439746, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.6538461538461539

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7487315010570825, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=100):
Best accuracy: 0.7556553911205074, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7944503171247357, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7373150105708245, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7564102564102564

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7600951374207188, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.7692307692307693

Step Backward Feature Selection with LogisticRegression(random_state=100) to select 74 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.79223044397463, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7852536997885835, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7144820295983088, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.6345665961945033, best hyperparameter: {'n_neighbors': 3, 'weights': 'distance'}
Accuracy on test set: 0.5641025641025641

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7671247357293869, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=100):
Best accuracy: 0.7533826638477801, best hyperparameter: {'C': 5, 'kernel': 'rbf'}
Accuracy on test set: 0.7435897435897436

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.764799154334038, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8076923076923077

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7417547568710359, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7948717948717948

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7554439746300212, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7692307692307693

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 74 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.755708245243129, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7579281183932347, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7031712473572939, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7564102564102564

Result of KNeighborsClassifier():
Best accuracy: 0.6322410147991544, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.5897435897435898

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7375264270613107, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=100):
Best accuracy: 0.7465644820295984, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7396405919661734, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.741860465116279, best hyperparameter: {'max_depth': None, 'n_estimators': 30}
Accuracy on test set: 0.8076923076923077

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7168604651162791, best hyperparameter: {'max_depth': None, 'n_estimators': 30}
Accuracy on test set: 0.7692307692307693

Step Backward Feature Selection with AdaBoostClassifier(random_state=100) to select 74 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7715116279069767, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8333333333333334

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7737843551797041, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7303911205073996, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.6439746300211417, best hyperparameter: {'n_neighbors': 9, 'weights': 'uniform'}
Accuracy on test set: 0.6410256410256411

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7487315010570824, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=100):
Best accuracy: 0.7647463002114165, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7948717948717948

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7944503171247357, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7600951374207189, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.7564102564102564

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7624735729386891, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.782051282051282

Step Backward Feature Selection with LogisticRegression(random_state=100) to select 75 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7945031712473571, best hyperparameter: {'C': 1, 'max_iter': 100}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7875264270613107, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7168076109936575, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.6302325581395349, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6282051282051282

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7602536997885835, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=100):
Best accuracy: 0.7489957716701902, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7948717948717948

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7602008456659619, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8205128205128205

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7623678646934461, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7564102564102564

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7533298097251586, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.8076923076923077

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 75 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7556553911205073, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7579281183932347, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.6987843551797039, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7564102564102564

Result of KNeighborsClassifier():
Best accuracy: 0.6096194503171247, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6282051282051282

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7306025369978858, best hyperparameter: {'solver': 'lsqr'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=100):
Best accuracy: 0.7579809725158562, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7350951374207189, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7258985200845666, best hyperparameter: {'max_depth': None, 'n_estimators': 30}
Accuracy on test set: 0.782051282051282

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7485200845665962, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.7948717948717948

Step Backward Feature Selection with AdaBoostClassifier(random_state=100) to select 75 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7715644820295982, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7737843551797041, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7235729386892178, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.6506342494714588, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6410256410256411

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7487315010570824, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=100):
Best accuracy: 0.757875264270613, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7948717948717948

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7944503171247357, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.74392177589852, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.8076923076923077

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7763213530655391, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.7948717948717948

Step Backward Feature Selection with LogisticRegression(random_state=100) to select 76 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7945031712473571, best hyperparameter: {'C': 1, 'max_iter': 100}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7875264270613107, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7190803382663847, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.6326109936575054, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6282051282051282

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7534355179704016, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8076923076923077

Result of SVC(random_state=100):
Best accuracy: 0.7466701902748414, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7648520084566595, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8205128205128205

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7418076109936576, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7307692307692307

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7553382663847781, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.7564102564102564

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 76 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.757875264270613, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7602008456659618, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7009513742071882, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7564102564102564

Result of KNeighborsClassifier():
Best accuracy: 0.6095137420718816, best hyperparameter: {'n_neighbors': 3, 'weights': 'distance'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.735200845665962, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=100):
Best accuracy: 0.764904862579281, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7373150105708246, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.8333333333333334

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7326638477801268, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7564102564102564

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7236257928118394, best hyperparameter: {'max_depth': 20, 'n_estimators': 80}
Accuracy on test set: 0.7435897435897436

Step Backward Feature Selection with AdaBoostClassifier(random_state=100) to select 76 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.773890063424947, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7737843551797041, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7392706131078224, best hyperparameter: {'class_weight': None, 'max_depth': None}
Accuracy on test set: 0.6923076923076923

Result of KNeighborsClassifier():
Best accuracy: 0.6506342494714589, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.6282051282051282

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7441331923890063, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=100):
Best accuracy: 0.7624735729386892, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7948717948717948

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7944503171247357, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7260042283298097, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.717948717948718

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.748678646934461, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.7692307692307693

Step Backward Feature Selection with LogisticRegression(random_state=100) to select 77 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7876321353065538, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7829809725158562, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7052854122621565, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.6326638477801269, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6282051282051282

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.751215644820296, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=100):
Best accuracy: 0.7534883720930232, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7948717948717948

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7511099365750529, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8076923076923077

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7440274841437633, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.7435897435897436

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7486257928118394, best hyperparameter: {'max_depth': None, 'n_estimators': 30}
Accuracy on test set: 0.7307692307692307

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 77 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7557082452431289, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7532241014799156, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.6986786469344609, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7564102564102564

Result of KNeighborsClassifier():
Best accuracy: 0.6096723044397464, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6666666666666666

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7374207188160676, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=100):
Best accuracy: 0.755813953488372, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.8076923076923077

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7352008456659619, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7948717948717948

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7419661733615222, best hyperparameter: {'max_depth': None, 'n_estimators': 30}
Accuracy on test set: 0.7307692307692307

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7165961945031714, best hyperparameter: {'max_depth': 20, 'n_estimators': 80}
Accuracy on test set: 0.7435897435897436

Step Backward Feature Selection with AdaBoostClassifier(random_state=100) to select 77 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7715644820295983, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7737843551797041, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7326638477801268, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.6437632135306555, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7441860465116279, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=100):
Best accuracy: 0.7647463002114165, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7948717948717948

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7944503171247357, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7372093023255814, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7307692307692307

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7556025369978859, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7948717948717948

Step Backward Feature Selection with LogisticRegression(random_state=100) to select 78 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7876321353065538, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7784355179704017, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7122621564482029, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.6325052854122621, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7466173361522198, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=100):
Best accuracy: 0.7489429175475687, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7579281183932347, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8205128205128205

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7372093023255814, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.7435897435897436

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7465116279069767, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7307692307692307

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 78 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7579809725158562, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8333333333333334

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7600951374207189, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7055496828752644, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7564102564102564

Result of KNeighborsClassifier():
Best accuracy: 0.6141649048625794, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6410256410256411

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7351479915433403, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=100):
Best accuracy: 0.7535412262156449, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7948717948717948

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7442389006342494, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.782051282051282

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7260570824524313, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7692307692307693

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7374207188160677, best hyperparameter: {'max_depth': 20, 'n_estimators': 80}
Accuracy on test set: 0.7307692307692307

Step Backward Feature Selection with AdaBoostClassifier(random_state=100) to select 78 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7715116279069767, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7737843551797041, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7303911205073996, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7435897435897436

Result of KNeighborsClassifier():
Best accuracy: 0.6414904862579281, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7510570824524312, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=100):
Best accuracy: 0.7647463002114165, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7948717948717948

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7921775898520084, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7532241014799154, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.7435897435897436

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7441331923890064, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.8076923076923077

Step Backward Feature Selection with LogisticRegression(random_state=100) to select 79 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7876321353065538, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7807082452431289, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7236257928118394, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.6302854122621565, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.5897435897435898

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7488372093023254, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=100):
Best accuracy: 0.751215644820296, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7602008456659619, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8076923076923077

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7373678646934461, best hyperparameter: {'max_depth': None, 'n_estimators': 30}
Accuracy on test set: 0.7435897435897436

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7487315010570823, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7948717948717948

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 79 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7648520084566597, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.753276955602537, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7054968287526427, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.6073467230443976, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7375264270613109, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=100):
Best accuracy: 0.7626321353065538, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.8076923076923077

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7419133192389007, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.8205128205128205

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7465644820295981, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.782051282051282

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7282241014799153, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7564102564102564

Step Backward Feature Selection with AdaBoostClassifier(random_state=100) to select 79 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7783826638477801, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7737843551797041, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7281712473572939, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.6414376321353066, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.5769230769230769

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7533298097251586, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=100):
Best accuracy: 0.7624735729386892, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.8076923076923077

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7899048625792812, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7394291754756872, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.717948717948718

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7625264270613108, best hyperparameter: {'max_depth': 10, 'n_estimators': 30}
Accuracy on test set: 0.7435897435897436

Step Backward Feature Selection with LogisticRegression(random_state=100) to select 80 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7830866807610993, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7784355179704017, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7145348837209302, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.6347251585623679, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.5769230769230769

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7466173361522198, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=100):
Best accuracy: 0.7581395348837209, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7533298097251586, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8076923076923077

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.728171247357294, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.782051282051282

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7553911205073995, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.8076923076923077

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=100) to select 80 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7625792811839324, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.753276955602537, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7078752642706131, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.6140591966173362, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.6025641025641025

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7352536997885835, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=100):
Best accuracy: 0.7649048625792811, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.8076923076923077

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7373678646934461, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.782051282051282

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7279598308668076, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.8333333333333334

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7258985200845666, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.7692307692307693

Step Backward Feature Selection with AdaBoostClassifier(random_state=100) to select 80 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7760042283298098, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7691860465116279, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7281183932346724, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.6460887949260041, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.5897435897435898

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7556553911205074, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=100):
Best accuracy: 0.769397463002114, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.8076923076923077

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7876321353065538, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7325052854122622, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.782051282051282

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7487315010570824, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7564102564102564

Select Feature Importance with LogisticRegression(C=1000, random_state=100) completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8081923890063425, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.8056553911205073, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.8333333333333334

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7328224101479915, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.717948717948718

Result of KNeighborsClassifier():
Best accuracy: 0.6801268498942917, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.7051282051282052

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7921775898520084, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=100):
Best accuracy: 0.8057610993657505, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.8589743589743589

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7876321353065538, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.8205128205128205

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7758985200845666, best hyperparameter: {'max_depth': 5, 'n_estimators': 80}
Accuracy on test set: 0.7692307692307693

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7853594080338265, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.8461538461538461

Select Feature Importance with DecisionTreeClassifier(random_state=100) completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7854651162790697, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7923361522198731, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7396405919661734, best hyperparameter: {'class_weight': None, 'max_depth': None}
Accuracy on test set: 0.6923076923076923

Result of KNeighborsClassifier():
Best accuracy: 0.7373150105708246, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.7307692307692307

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7716701902748413, best hyperparameter: {'solver': 'lsqr'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=100):
Best accuracy: 0.780813953488372, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7670190274841436, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.782051282051282

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.773784355179704, best hyperparameter: {'max_depth': 5, 'n_estimators': 80}
Accuracy on test set: 0.7564102564102564

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7876849894291753, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.8076923076923077

Select Feature Importance with RandomForestClassifier(random_state=100) completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7921775898520084, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8333333333333334

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7944503171247357, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7234143763213531, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 10}
Accuracy on test set: 0.7051282051282052

Result of KNeighborsClassifier():
Best accuracy: 0.7170718816067654, best hyperparameter: {'n_neighbors': 9, 'weights': 'uniform'}
Accuracy on test set: 0.782051282051282

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7784355179704017, best hyperparameter: {'solver': 'lsqr'}
Accuracy on test set: 0.8076923076923077

Result of SVC(random_state=100):
Best accuracy: 0.7921247357293868, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.8205128205128205

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7921775898520084, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8717948717948718

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7873678646934461, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.782051282051282

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7966173361522199, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7948717948717948

Select Feature Importance with AdaBoostClassifier(random_state=100) completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.780813953488372, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.8846153846153846

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7829809725158562, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8589743589743589

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.702801268498943, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6923076923076923

Result of KNeighborsClassifier():
Best accuracy: 0.7077167019027485, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.7564102564102564

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7715116279069767, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8589743589743589

Result of SVC(random_state=100):
Best accuracy: 0.7806025369978858, best hyperparameter: {'C': 10, 'kernel': 'rbf'}
Accuracy on test set: 0.8461538461538461

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7762684989429175, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.7307692307692307

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7876321353065538, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.8076923076923077

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.8124207188160677, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.8717948717948718

Recursive Feature Addition with LogisticRegression(random_state=100) completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.8353594080338265, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.8717948717948718

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.821723044397463, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.8589743589743589

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7462473572938689, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.717948717948718

Result of KNeighborsClassifier():
Best accuracy: 0.7441331923890064, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.8333333333333334

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.810306553911205, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8846153846153846

Result of SVC(random_state=100):
Best accuracy: 0.8080338266384777, best hyperparameter: {'C': 1, 'kernel': 'linear'}
Accuracy on test set: 0.8461538461538461

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.821828752642706, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.8461538461538461

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7942389006342495, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.8333333333333334

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.8035940803382664, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.8461538461538461

Recursive Feature Addition with DecisionTreeClassifier(random_state=100) completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7419133192389007, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7435897435897436

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.744186046511628, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.7564102564102564

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7372093023255815, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 5}
Accuracy on test set: 0.7051282051282052

Result of KNeighborsClassifier():
Best accuracy: 0.7234672304439747, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6794871794871795

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7373678646934462, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=100):
Best accuracy: 0.7510570824524313, best hyperparameter: {'C': 1, 'kernel': 'poly'}
Accuracy on test set: 0.717948717948718

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7372621564482029, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.7307692307692307

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7373150105708246, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.6794871794871795

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7396405919661735, best hyperparameter: {'max_depth': 5, 'n_estimators': 10}
Accuracy on test set: 0.6410256410256411

Recursive Feature Addition with RandomForestClassifier(random_state=100) completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7897991543340381, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.7853065539112051, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.728276955602537, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6410256410256411

Result of KNeighborsClassifier():
Best accuracy: 0.7281712473572939, best hyperparameter: {'n_neighbors': 9, 'weights': 'uniform'}
Accuracy on test set: 0.717948717948718

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7875792811839324, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8333333333333334

Result of SVC(random_state=100):
Best accuracy: 0.7830866807610993, best hyperparameter: {'C': 50, 'kernel': 'linear'}
Accuracy on test set: 0.8205128205128205

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.7761627906976745, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.7760570824524311, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.7692307692307693

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.7830866807610993, best hyperparameter: {'max_depth': 5, 'n_estimators': 80}
Accuracy on test set: 0.782051282051282

Recursive Feature Addition with AdaBoostClassifier(random_state=100) completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=100):
Best accuracy: 0.7968287526427061, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8461538461538461

Result of RidgeClassifier(random_state=100):
Best accuracy: 0.8014270613107822, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8461538461538461

Result of DecisionTreeClassifier(random_state=100):
Best accuracy: 0.7439746300211417, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.7692307692307693

Result of KNeighborsClassifier():
Best accuracy: 0.794397463002114, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.8589743589743589

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7922304439746299, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8846153846153846

Result of SVC(random_state=100):
Best accuracy: 0.8011099365750528, best hyperparameter: {'C': 1, 'kernel': 'rbf'}
Accuracy on test set: 0.8589743589743589

Result of AdaBoostClassifier(random_state=100):
Best accuracy: 0.805708245243129, best hyperparameter: {'estimator': None, 'n_estimators': 80}
Accuracy on test set: 0.7692307692307693

Result of RandomForestClassifier(random_state=100):
Best accuracy: 0.8080866807610994, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.8333333333333334

Result of ExtraTreesClassifier(random_state=100):
Best accuracy: 0.8033826638477801, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.8589743589743589

