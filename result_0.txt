Correlation Feature Selector with selection method=variance completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7713530655391121, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7804439746300211, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7214059196617336, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 10}
Accuracy on test set: 0.6025641025641025

Result of KNeighborsClassifier():
Best accuracy: 0.6299682875264271, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.5769230769230769

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7599365750528542, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8076923076923077

Result of SVC(random_state=0):
Best accuracy: 0.7438689217758986, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7552325581395349, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.782051282051282

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7646934460887949, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6410256410256411

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7967758985200846, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.7051282051282052

Correlation Feature Selector with selection method=cardinality completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.771247357293869, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7804968287526428, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7348837209302326, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.6410256410256411

Result of KNeighborsClassifier():
Best accuracy: 0.6345665961945033, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.5641025641025641

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7599365750528542, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8076923076923077

Result of SVC(random_state=0):
Best accuracy: 0.7438689217758986, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7552325581395349, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.782051282051282

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7556553911205073, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6666666666666666

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7876321353065538, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.6923076923076923

Statistical Feature Selector with method=mi completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8079809725158562, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8148520084566595, best hyperparameter: {'alpha': 1, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7353594080338265, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.6794871794871795

Result of KNeighborsClassifier():
Best accuracy: 0.7577695560253701, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6923076923076923

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8169661733615221, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=0):
Best accuracy: 0.8193974630021141, best hyperparameter: {'C': 5, 'kernel': 'rbf'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8101479915433403, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7435897435897436

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.8172832980972515, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.6794871794871795

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8242071881606765, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.7307692307692307

Statistical Feature Selector with method=anova completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7989957716701902, best hyperparameter: {'C': 1, 'max_iter': 100}
Accuracy on test set: 0.7435897435897436

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8058668076109935, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7564102564102564

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7352008456659618, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.6666666666666666

Result of KNeighborsClassifier():
Best accuracy: 0.6507928118393235, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.6025641025641025

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7921247357293868, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=0):
Best accuracy: 0.7852008456659619, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.8076923076923077

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7759513742071882, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7307692307692307

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7945031712473571, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.6538461538461539

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.796828752642706, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7051282051282052

Step Forward Feature Selection with LogisticRegression(random_state=0) to select 5 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8217758985200845, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8126849894291756, best hyperparameter: {'alpha': 5, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7464059196617335, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7051282051282052

Result of KNeighborsClassifier():
Best accuracy: 0.7919661733615223, best hyperparameter: {'n_neighbors': 3, 'weights': 'uniform'}
Accuracy on test set: 0.6410256410256411

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7897991543340381, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=0):
Best accuracy: 0.8127906976744186, best hyperparameter: {'C': 5, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8080338266384779, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.7435897435897436

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7966173361522199, best hyperparameter: {'max_depth': 5, 'n_estimators': 10}
Accuracy on test set: 0.6794871794871795

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8012156448202961, best hyperparameter: {'max_depth': 5, 'n_estimators': 30}
Accuracy on test set: 0.6923076923076923

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 5 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.805813953488372, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7966701902748413, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.782051282051282

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7484672304439747, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.6538461538461539

Result of KNeighborsClassifier():
Best accuracy: 0.8124207188160677, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.7051282051282052

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8012684989429175, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=0):
Best accuracy: 0.8125264270613108, best hyperparameter: {'C': 5, 'kernel': 'rbf'}
Accuracy on test set: 0.7435897435897436

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7989429175475686, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.7307692307692307

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.798678646934461, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.717948717948718

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7966701902748413, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.717948717948718

Step Forward Feature Selection with AdaBoostClassifier(random_state=0) to select 5 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8080866807610994, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8012684989429175, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7564102564102564

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7761627906976745, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.6282051282051282

Result of KNeighborsClassifier():
Best accuracy: 0.7874735729386892, best hyperparameter: {'n_neighbors': 5, 'weights': 'uniform'}
Accuracy on test set: 0.6666666666666666

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7965644820295983, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=0):
Best accuracy: 0.8104651162790697, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7307692307692307

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8034883720930232, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.7435897435897436

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.8079809725158562, best hyperparameter: {'max_depth': 5, 'n_estimators': 30}
Accuracy on test set: 0.7051282051282052

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7990486257928119, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.6666666666666666

Step Forward Feature Selection with LogisticRegression(random_state=0) to select 6 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8286469344608879, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8126849894291756, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7487315010570824, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7051282051282052

Result of KNeighborsClassifier():
Best accuracy: 0.78276955602537, best hyperparameter: {'n_neighbors': 9, 'weights': 'uniform'}
Accuracy on test set: 0.7051282051282052

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7988900634249471, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=0):
Best accuracy: 0.8105179704016912, best hyperparameter: {'C': 1, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8149048625792812, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.7435897435897436

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.8012684989429175, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.7564102564102564

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8079809725158562, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.717948717948718

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 6 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8034355179704017, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.7307692307692307

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7989429175475687, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7435897435897436

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7349365750528541, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.6923076923076923

Result of KNeighborsClassifier():
Best accuracy: 0.7942389006342494, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6666666666666666

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7988900634249472, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=0):
Best accuracy: 0.8033826638477801, best hyperparameter: {'C': 10, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7874207188160677, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.7435897435897436

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7965644820295982, best hyperparameter: {'max_depth': None, 'n_estimators': 30}
Accuracy on test set: 0.717948717948718

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8011627906976744, best hyperparameter: {'max_depth': 5, 'n_estimators': 80}
Accuracy on test set: 0.717948717948718

Step Forward Feature Selection with AdaBoostClassifier(random_state=0) to select 6 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8150105708245242, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.717948717948718

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.812737843551797, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7307692307692307

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7464587737843552, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 10}
Accuracy on test set: 0.6538461538461539

Result of KNeighborsClassifier():
Best accuracy: 0.7875264270613107, best hyperparameter: {'n_neighbors': 5, 'weights': 'uniform'}
Accuracy on test set: 0.7051282051282052

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.801109936575053, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=0):
Best accuracy: 0.8218816067653277, best hyperparameter: {'C': 1, 'kernel': 'linear'}
Accuracy on test set: 0.6923076923076923

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8194503171247357, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 100}
Accuracy on test set: 0.7435897435897436

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.8058139534883721, best hyperparameter: {'max_depth': 5, 'n_estimators': 80}
Accuracy on test set: 0.717948717948718

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8014270613107822, best hyperparameter: {'max_depth': 5, 'n_estimators': 10}
Accuracy on test set: 0.7051282051282052

Step Forward Feature Selection with LogisticRegression(random_state=0) to select 7 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8331923890063425, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8104122621564482, best hyperparameter: {'alpha': 5, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7441860465116279, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6666666666666666

Result of KNeighborsClassifier():
Best accuracy: 0.7829281183932346, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6410256410256411

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7942917547568711, best hyperparameter: {'solver': 'lsqr'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=0):
Best accuracy: 0.8127906976744186, best hyperparameter: {'C': 1, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8012156448202961, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7435897435897436

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7943446088794925, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.7051282051282052

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8126849894291753, best hyperparameter: {'max_depth': 5, 'n_estimators': 30}
Accuracy on test set: 0.6794871794871795

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 7 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8171247357293868, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.7435897435897436

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.805813953488372, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.7435897435897436

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.757875264270613, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.6538461538461539

Result of KNeighborsClassifier():
Best accuracy: 0.7874735729386891, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.717948717948718

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8033298097251587, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=0):
Best accuracy: 0.8127906976744186, best hyperparameter: {'C': 50, 'kernel': 'linear'}
Accuracy on test set: 0.7307692307692307

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8011099365750528, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.814693446088795, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.6538461538461539

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8148520084566597, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.7307692307692307

Step Forward Feature Selection with AdaBoostClassifier(random_state=0) to select 7 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8263742071881606, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.7564102564102564

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8195560253699788, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.7435897435897436

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.739693446088795, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 10}
Accuracy on test set: 0.6025641025641025

Result of KNeighborsClassifier():
Best accuracy: 0.7783826638477802, best hyperparameter: {'n_neighbors': 9, 'weights': 'uniform'}
Accuracy on test set: 0.6794871794871795

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8012156448202958, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=0):
Best accuracy: 0.8242071881606765, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7051282051282052

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.821828752642706, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 50}
Accuracy on test set: 0.7435897435897436

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.8011627906976744, best hyperparameter: {'max_depth': None, 'n_estimators': 30}
Accuracy on test set: 0.6923076923076923

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8012156448202958, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.717948717948718

Step Forward Feature Selection with LogisticRegression(random_state=0) to select 8 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8309725158562367, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8035940803382664, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7419661733615223, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6794871794871795

Result of KNeighborsClassifier():
Best accuracy: 0.7599365750528542, best hyperparameter: {'n_neighbors': 5, 'weights': 'uniform'}
Accuracy on test set: 0.6410256410256411

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7965644820295983, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=0):
Best accuracy: 0.812737843551797, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7966701902748414, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7435897435897436

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7828752642706129, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.6923076923076923

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.801321353065539, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.6794871794871795

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 8 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8172832980972515, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.7307692307692307

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8012684989429175, best hyperparameter: {'alpha': 0.5, 'max_iter': None}
Accuracy on test set: 0.7307692307692307

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7417547568710361, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.7051282051282052

Result of KNeighborsClassifier():
Best accuracy: 0.7898520084566595, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.7051282051282052

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7965644820295982, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7435897435897436

Result of SVC(random_state=0):
Best accuracy: 0.8082452431289641, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.717948717948718

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8035940803382664, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.8010570824524313, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.6538461538461539

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.796723044397463, best hyperparameter: {'max_depth': 5, 'n_estimators': 10}
Accuracy on test set: 0.6794871794871795

Step Forward Feature Selection with AdaBoostClassifier(random_state=0) to select 8 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8172832980972515, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.717948717948718

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.817336152219873, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.717948717948718

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7372621564482029, best hyperparameter: {'class_weight': None, 'max_depth': None}
Accuracy on test set: 0.6923076923076923

Result of KNeighborsClassifier():
Best accuracy: 0.7669661733615223, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6538461538461539

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8034355179704017, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7435897435897436

Result of SVC(random_state=0):
Best accuracy: 0.8193974630021141, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.6923076923076923

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8195031712473572, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 50}
Accuracy on test set: 0.7435897435897436

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.8013742071881607, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.6538461538461539

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7966701902748413, best hyperparameter: {'max_depth': 5, 'n_estimators': 10}
Accuracy on test set: 0.7435897435897436

Step Forward Feature Selection with LogisticRegression(random_state=0) to select 9 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8332452431289641, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7989429175475686, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.782051282051282

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7442389006342494, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6923076923076923

Result of KNeighborsClassifier():
Best accuracy: 0.7690803382663849, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.6410256410256411

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8034355179704017, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=0):
Best accuracy: 0.8196088794926004, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8012684989429175, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7435897435897436

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7921775898520084, best hyperparameter: {'max_depth': 5, 'n_estimators': 30}
Accuracy on test set: 0.6923076923076923

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8057610993657505, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.7051282051282052

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 9 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8126849894291753, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7307692307692307

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.796723044397463, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.7307692307692307

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7440274841437633, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.6794871794871795

Result of KNeighborsClassifier():
Best accuracy: 0.780708245243129, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.7051282051282052

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7965644820295982, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7435897435897436

Result of SVC(random_state=0):
Best accuracy: 0.8081923890063424, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7307692307692307

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7990486257928119, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7964587737843554, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.6538461538461539

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8124735729386892, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.6538461538461539

Step Forward Feature Selection with AdaBoostClassifier(random_state=0) to select 9 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8149048625792812, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.717948717948718

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.812737843551797, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.717948717948718

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7395877378435518, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.7051282051282052

Result of KNeighborsClassifier():
Best accuracy: 0.7442389006342495, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.6794871794871795

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7965644820295983, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7435897435897436

Result of SVC(random_state=0):
Best accuracy: 0.8171775898520084, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.6923076923076923

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8173361522198732, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6794871794871795

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.8056553911205073, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.7307692307692307

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8034355179704017, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.6666666666666666

Step Forward Feature Selection with LogisticRegression(random_state=0) to select 10 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8310782241014799, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.805813953488372, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.782051282051282

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7419133192389006, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7051282051282052

Result of KNeighborsClassifier():
Best accuracy: 0.7394820295983087, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6282051282051282

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8011627906976744, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=0):
Best accuracy: 0.8218816067653277, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7966701902748413, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.785200845665962, best hyperparameter: {'max_depth': 5, 'n_estimators': 30}
Accuracy on test set: 0.6794871794871795

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.805813953488372, best hyperparameter: {'max_depth': 5, 'n_estimators': 30}
Accuracy on test set: 0.717948717948718

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 10 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8171775898520084, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7435897435897436

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.810306553911205, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7564102564102564

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.737262156448203, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6666666666666666

Result of KNeighborsClassifier():
Best accuracy: 0.7897463002114165, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6410256410256411

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8034355179704017, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7307692307692307

Result of SVC(random_state=0):
Best accuracy: 0.8080338266384777, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7051282051282052

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7989957716701902, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.810306553911205, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.6538461538461539

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8078752642706132, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6538461538461539

Step Forward Feature Selection with AdaBoostClassifier(random_state=0) to select 10 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8125264270613108, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.717948717948718

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.812737843551797, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7307692307692307

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.748678646934461, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.7051282051282052

Result of KNeighborsClassifier():
Best accuracy: 0.7487843551797042, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.6794871794871795

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7965644820295983, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7435897435897436

Result of SVC(random_state=0):
Best accuracy: 0.8148520084566595, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.6923076923076923

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8196088794926004, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6794871794871795

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.8148520084566595, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.6923076923076923

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7966173361522199, best hyperparameter: {'max_depth': 5, 'n_estimators': 80}
Accuracy on test set: 0.717948717948718

Step Forward Feature Selection with LogisticRegression(random_state=0) to select 11 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8309196617336152, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7435897435897436

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8126321353065539, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7435897435897436

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7419133192389006, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6666666666666666

Result of KNeighborsClassifier():
Best accuracy: 0.7530655391120508, best hyperparameter: {'n_neighbors': 9, 'weights': 'uniform'}
Accuracy on test set: 0.6794871794871795

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8102536997885835, best hyperparameter: {'solver': 'lsqr'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=0):
Best accuracy: 0.8332452431289641, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7051282051282052

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8011627906976744, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6282051282051282

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7852008456659618, best hyperparameter: {'max_depth': 5, 'n_estimators': 80}
Accuracy on test set: 0.6923076923076923

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8011627906976744, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.717948717948718

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 11 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8103594080338267, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.7435897435897436

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8125792811839323, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.7564102564102564

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7440803382663848, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6666666666666666

Result of KNeighborsClassifier():
Best accuracy: 0.7783298097251585, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.7051282051282052

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7988372093023256, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7435897435897436

Result of SVC(random_state=0):
Best accuracy: 0.7921775898520084, best hyperparameter: {'C': 1, 'kernel': 'linear'}
Accuracy on test set: 0.7435897435897436

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.796828752642706, best hyperparameter: {'estimator': None, 'n_estimators': 10}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.8125792811839325, best hyperparameter: {'max_depth': None, 'n_estimators': 30}
Accuracy on test set: 0.6666666666666666

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8079281183932346, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.7051282051282052

Step Forward Feature Selection with AdaBoostClassifier(random_state=0) to select 11 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8125792811839322, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.7307692307692307

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8104651162790697, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7307692307692307

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7439746300211418, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.717948717948718

Result of KNeighborsClassifier():
Best accuracy: 0.7395348837209303, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6538461538461539

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7920190274841438, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=0):
Best accuracy: 0.8148520084566595, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7051282051282052

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8196088794926004, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6794871794871795

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.805813953488372, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.717948717948718

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.794291754756871, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.717948717948718

Step Forward Feature Selection with LogisticRegression(random_state=0) to select 12 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8355179704016914, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7564102564102564

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8172832980972515, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.7435897435897436

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7304968287526428, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6538461538461539

Result of KNeighborsClassifier():
Best accuracy: 0.7576109936575053, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.6923076923076923

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8057610993657505, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7435897435897436

Result of SVC(random_state=0):
Best accuracy: 0.8241543340380548, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.717948717948718

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8079809725158563, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.6923076923076923

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7989957716701902, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.6538461538461539

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8012684989429175, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.6794871794871795

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 12 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8217758985200845, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7307692307692307

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.812737843551797, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7564102564102564

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7648520084566595, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 10}
Accuracy on test set: 0.6794871794871795

Result of KNeighborsClassifier():
Best accuracy: 0.7966173361522199, best hyperparameter: {'n_neighbors': 9, 'weights': 'uniform'}
Accuracy on test set: 0.6794871794871795

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8080866807610994, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=0):
Best accuracy: 0.8193974630021141, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8126849894291756, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.8236786469344608, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.7051282051282052

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.821723044397463, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.7435897435897436

Step Forward Feature Selection with AdaBoostClassifier(random_state=0) to select 12 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.812737843551797, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7435897435897436

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8104651162790697, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7307692307692307

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7349894291754758, best hyperparameter: {'class_weight': None, 'max_depth': None}
Accuracy on test set: 0.6923076923076923

Result of KNeighborsClassifier():
Best accuracy: 0.7373678646934462, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.6794871794871795

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7965644820295982, best hyperparameter: {'solver': 'lsqr'}
Accuracy on test set: 0.7435897435897436

Result of SVC(random_state=0):
Best accuracy: 0.8148520084566595, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7051282051282052

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8196088794926004, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6794871794871795

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7898520084566595, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.6923076923076923

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7945031712473571, best hyperparameter: {'max_depth': 5, 'n_estimators': 30}
Accuracy on test set: 0.717948717948718

Step Forward Feature Selection with LogisticRegression(random_state=0) to select 13 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8355708245243129, best hyperparameter: {'C': 5, 'max_iter': 50}
Accuracy on test set: 0.7564102564102564

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8171775898520084, best hyperparameter: {'alpha': 5, 'max_iter': None}
Accuracy on test set: 0.7435897435897436

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7396405919661733, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.6153846153846154

Result of KNeighborsClassifier():
Best accuracy: 0.7460359408033826, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6923076923076923

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8034883720930232, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7435897435897436

Result of SVC(random_state=0):
Best accuracy: 0.8218816067653277, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.717948717948718

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8056553911205075, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7051282051282052

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.776215644820296, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.6538461538461539

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7920718816067653, best hyperparameter: {'max_depth': 5, 'n_estimators': 80}
Accuracy on test set: 0.717948717948718

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 13 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8354651162790697, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7051282051282052

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8285940803382663, best hyperparameter: {'alpha': 0.5, 'max_iter': None}
Accuracy on test set: 0.782051282051282

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7669661733615222, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 10}
Accuracy on test set: 0.6666666666666666

Result of KNeighborsClassifier():
Best accuracy: 0.7897463002114165, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.717948717948718

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8102536997885835, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7435897435897436

Result of SVC(random_state=0):
Best accuracy: 0.8308139534883721, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8103594080338267, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 50}
Accuracy on test set: 0.7307692307692307

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.8147463002114165, best hyperparameter: {'max_depth': None, 'n_estimators': 10}
Accuracy on test set: 0.6282051282051282

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8263742071881607, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.717948717948718

Step Forward Feature Selection with AdaBoostClassifier(random_state=0) to select 13 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.812737843551797, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7435897435897436

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8148520084566595, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.7307692307692307

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7463002114164905, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.717948717948718

Result of KNeighborsClassifier():
Best accuracy: 0.741754756871036, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6410256410256411

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8010570824524311, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7435897435897436

Result of SVC(random_state=0):
Best accuracy: 0.8171247357293868, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7051282051282052

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8196088794926004, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6794871794871795

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.8013742071881605, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.7307692307692307

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8011627906976744, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.7307692307692307

Step Forward Feature Selection with LogisticRegression(random_state=0) to select 14 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8378435517970402, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7435897435897436

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8149577167019026, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7307692307692307

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7304968287526428, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6410256410256411

Result of KNeighborsClassifier():
Best accuracy: 0.7347780126849894, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6794871794871795

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8034883720930232, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7435897435897436

Result of SVC(random_state=0):
Best accuracy: 0.8216701902748413, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.717948717948718

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8059196617336152, best hyperparameter: {'estimator': None, 'n_estimators': 30}
Accuracy on test set: 0.6794871794871795

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7967230443974629, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.6538461538461539

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.796723044397463, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6923076923076923

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 14 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8354651162790697, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7051282051282052

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8331923890063425, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.741860465116279, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.6666666666666666

Result of KNeighborsClassifier():
Best accuracy: 0.7806025369978858, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.717948717948718

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8102536997885835, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7435897435897436

Result of SVC(random_state=0):
Best accuracy: 0.8217758985200845, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8104651162790697, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.7307692307692307

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.8285412262156449, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6794871794871795

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8263742071881607, best hyperparameter: {'max_depth': 5, 'n_estimators': 30}
Accuracy on test set: 0.7307692307692307

Step Forward Feature Selection with AdaBoostClassifier(random_state=0) to select 14 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.812737843551797, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7307692307692307

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8104122621564482, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.7307692307692307

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7395877378435518, best hyperparameter: {'class_weight': None, 'max_depth': None}
Accuracy on test set: 0.6794871794871795

Result of KNeighborsClassifier():
Best accuracy: 0.7372621564482029, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6538461538461539

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.798784355179704, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7435897435897436

Result of SVC(random_state=0):
Best accuracy: 0.810200845665962, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7051282051282052

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8196088794926004, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6794871794871795

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.8034883720930232, best hyperparameter: {'max_depth': 5, 'n_estimators': 30}
Accuracy on test set: 0.6794871794871795

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7852536997885835, best hyperparameter: {'max_depth': 5, 'n_estimators': 80}
Accuracy on test set: 0.717948717948718

Step Forward Feature Selection with LogisticRegression(random_state=0) to select 15 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8424418604651163, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7435897435897436

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8126849894291753, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7307692307692307

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7284883720930232, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.6538461538461539

Result of KNeighborsClassifier():
Best accuracy: 0.7371564482029599, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.717948717948718

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8057610993657505, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7435897435897436

Result of SVC(random_state=0):
Best accuracy: 0.8195560253699787, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.7307692307692307

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.805708245243129, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7829809725158562, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.7051282051282052

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7966701902748413, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.6923076923076923

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 15 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.826321353065539, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7307692307692307

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8355179704016914, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7564102564102564

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7693446088794926, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6153846153846154

Result of KNeighborsClassifier():
Best accuracy: 0.7899048625792812, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6666666666666666

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8170718816067654, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=0):
Best accuracy: 0.8149048625792812, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8195560253699788, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7051282051282052

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.8216701902748413, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7307692307692307

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8422832980972516, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.6794871794871795

Step Forward Feature Selection with AdaBoostClassifier(random_state=0) to select 15 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8150634249471459, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7307692307692307

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8104651162790697, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.6923076923076923

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7463002114164905, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.6794871794871795

Result of KNeighborsClassifier():
Best accuracy: 0.7304439746300211, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6794871794871795

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7942389006342495, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=0):
Best accuracy: 0.8035412262156447, best hyperparameter: {'C': 1, 'kernel': 'linear'}
Accuracy on test set: 0.717948717948718

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8196088794926004, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6794871794871795

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7943974630021142, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7051282051282052

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7966173361522199, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7051282051282052

Step Forward Feature Selection with LogisticRegression(random_state=0) to select 16 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8401691331923891, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.717948717948718

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8126849894291753, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7307692307692307

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7282241014799153, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6153846153846154

Result of KNeighborsClassifier():
Best accuracy: 0.7325581395348838, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.717948717948718

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8034883720930232, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7435897435897436

Result of SVC(random_state=0):
Best accuracy: 0.8241543340380548, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.7307692307692307

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8011099365750528, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7051282051282052

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7920190274841437, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.6794871794871795

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.801321353065539, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.6538461538461539

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 16 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.826321353065539, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.7564102564102564

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8355179704016914, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7580338266384777, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6025641025641025

Result of KNeighborsClassifier():
Best accuracy: 0.7624207188160677, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6282051282051282

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.821723044397463, best hyperparameter: {'solver': 'lsqr'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=0):
Best accuracy: 0.8241014799154334, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8195560253699788, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7307692307692307

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.8354651162790697, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.6923076923076923

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8260570824524314, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.7692307692307693

Step Forward Feature Selection with AdaBoostClassifier(random_state=0) to select 16 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.810306553911205, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.7564102564102564

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8059196617336152, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7307692307692307

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7214059196617336, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.7307692307692307

Result of KNeighborsClassifier():
Best accuracy: 0.7325581395348838, best hyperparameter: {'n_neighbors': 9, 'weights': 'uniform'}
Accuracy on test set: 0.7435897435897436

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7874207188160677, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7435897435897436

Result of SVC(random_state=0):
Best accuracy: 0.8216173361522199, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7307692307692307

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8103594080338266, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6923076923076923

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7945031712473571, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.7051282051282052

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7990486257928119, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.7307692307692307

Step Forward Feature Selection with LogisticRegression(random_state=0) to select 17 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8401691331923888, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7435897435897436

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8080866807610994, best hyperparameter: {'alpha': 5, 'max_iter': None}
Accuracy on test set: 0.7564102564102564

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7374735729386892, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.6538461538461539

Result of KNeighborsClassifier():
Best accuracy: 0.7234143763213531, best hyperparameter: {'n_neighbors': 9, 'weights': 'uniform'}
Accuracy on test set: 0.5769230769230769

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8057610993657505, best hyperparameter: {'solver': 'lsqr'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=0):
Best accuracy: 0.8263742071881606, best hyperparameter: {'C': 1, 'kernel': 'linear'}
Accuracy on test set: 0.717948717948718

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8057082452431288, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7966701902748413, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.6538461538461539

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7920718816067653, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6666666666666666

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 17 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8240486257928119, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.7435897435897436

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8264799154334039, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7488900634249471, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6153846153846154

Result of KNeighborsClassifier():
Best accuracy: 0.7415961945031713, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.6282051282051282

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.810306553911205, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=0):
Best accuracy: 0.8148520084566595, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8241014799154334, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.8490486257928118, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.7307692307692307

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8308668076109937, best hyperparameter: {'max_depth': 10, 'n_estimators': 30}
Accuracy on test set: 0.6794871794871795

Step Forward Feature Selection with AdaBoostClassifier(random_state=0) to select 17 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8058668076109937, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.7564102564102564

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8035940803382664, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.717948717948718

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7168076109936576, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 5}
Accuracy on test set: 0.6410256410256411

Result of KNeighborsClassifier():
Best accuracy: 0.7142177589852009, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.6923076923076923

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7919133192389005, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7435897435897436

Result of SVC(random_state=0):
Best accuracy: 0.8080866807610994, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.717948717948718

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.821723044397463, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6538461538461539

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7945031712473571, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.717948717948718

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.789799154334038, best hyperparameter: {'max_depth': 5, 'n_estimators': 30}
Accuracy on test set: 0.7692307692307693

Step Forward Feature Selection with LogisticRegression(random_state=0) to select 18 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8447145877378436, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.7564102564102564

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8058668076109937, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7435897435897436

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.723784355179704, best hyperparameter: {'class_weight': None, 'max_depth': None}
Accuracy on test set: 0.6666666666666666

Result of KNeighborsClassifier():
Best accuracy: 0.7323995771670191, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6410256410256411

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8080338266384777, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=0):
Best accuracy: 0.821828752642706, best hyperparameter: {'C': 1, 'kernel': 'linear'}
Accuracy on test set: 0.717948717948718

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8102536997885835, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7051282051282052

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7831395348837209, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.6538461538461539

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8034355179704017, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.7307692307692307

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 18 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8240486257928119, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.7435897435897436

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8218816067653277, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.782051282051282

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7443446088794926, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6282051282051282

Result of KNeighborsClassifier():
Best accuracy: 0.7487315010570825, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6538461538461539

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8102536997885835, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=0):
Best accuracy: 0.8149577167019026, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7435897435897436

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8286469344608879, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.8307610993657505, best hyperparameter: {'max_depth': None, 'n_estimators': 30}
Accuracy on test set: 0.6923076923076923

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8309196617336152, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.7307692307692307

Step Forward Feature Selection with AdaBoostClassifier(random_state=0) to select 18 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8035412262156448, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.7435897435897436

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8034355179704017, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.7435897435897436

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7418076109936576, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6923076923076923

Result of KNeighborsClassifier():
Best accuracy: 0.7144291754756871, best hyperparameter: {'n_neighbors': 9, 'weights': 'uniform'}
Accuracy on test set: 0.7051282051282052

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7941860465116279, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=0):
Best accuracy: 0.8193974630021141, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7307692307692307

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8125792811839323, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.7051282051282052

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7943974630021142, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.717948717948718

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7898520084566595, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7564102564102564

Step Forward Feature Selection with LogisticRegression(random_state=0) to select 19 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8424418604651163, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7564102564102564

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8058668076109937, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7435897435897436

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7420718816067653, best hyperparameter: {'class_weight': None, 'max_depth': None}
Accuracy on test set: 0.6923076923076923

Result of KNeighborsClassifier():
Best accuracy: 0.711997885835095, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6538461538461539

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8149577167019026, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=0):
Best accuracy: 0.8195560253699788, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7307692307692307

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8079809725158562, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.6923076923076923

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.789799154334038, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.6666666666666666

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8013742071881607, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.7307692307692307

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 19 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8263742071881607, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.7435897435897436

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8241543340380548, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.782051282051282

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7466173361522198, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6410256410256411

Result of KNeighborsClassifier():
Best accuracy: 0.7440274841437633, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6538461538461539

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8079809725158562, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=0):
Best accuracy: 0.8171247357293868, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8331923890063425, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.8262684989429175, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.6538461538461539

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8398520084566595, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.782051282051282

Step Forward Feature Selection with AdaBoostClassifier(random_state=0) to select 19 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8013742071881607, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7435897435897436

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8012156448202961, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7395348837209303, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6666666666666666

Result of KNeighborsClassifier():
Best accuracy: 0.6892706131078224, best hyperparameter: {'n_neighbors': 3, 'weights': 'distance'}
Accuracy on test set: 0.6794871794871795

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7896405919661735, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=0):
Best accuracy: 0.8149048625792812, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7435897435897436

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8149048625792812, best hyperparameter: {'estimator': None, 'n_estimators': 30}
Accuracy on test set: 0.6923076923076923

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.8059196617336152, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.6538461538461539

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7921775898520084, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.7307692307692307

Step Forward Feature Selection with LogisticRegression(random_state=0) to select 20 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8401691331923891, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7564102564102564

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8035940803382664, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7305496828752641, best hyperparameter: {'class_weight': None, 'max_depth': 10}
Accuracy on test set: 0.6410256410256411

Result of KNeighborsClassifier():
Best accuracy: 0.7144820295983088, best hyperparameter: {'n_neighbors': 9, 'weights': 'uniform'}
Accuracy on test set: 0.6666666666666666

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8012156448202961, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=0):
Best accuracy: 0.810306553911205, best hyperparameter: {'C': 1, 'kernel': 'linear'}
Accuracy on test set: 0.7051282051282052

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8079809725158562, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7051282051282052

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.789799154334038, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6923076923076923

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8150634249471459, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.6794871794871795

Step Forward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 20 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8286469344608879, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.7307692307692307

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8196088794926004, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7466173361522198, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6282051282051282

Result of KNeighborsClassifier():
Best accuracy: 0.7577167019027484, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6794871794871795

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8080338266384779, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=0):
Best accuracy: 0.8171247357293868, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8241014799154334, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.8284883720930232, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6794871794871795

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8283298097251585, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7051282051282052

Step Forward Feature Selection with AdaBoostClassifier(random_state=0) to select 20 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7989429175475686, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.717948717948718

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.796723044397463, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.717948717948718

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7509513742071883, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6794871794871795

Result of KNeighborsClassifier():
Best accuracy: 0.7054439746300212, best hyperparameter: {'n_neighbors': 9, 'weights': 'uniform'}
Accuracy on test set: 0.7307692307692307

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7942389006342493, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=0):
Best accuracy: 0.8035412262156447, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7435897435897436

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8284355179704017, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.7051282051282052

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7943446088794925, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.6666666666666666

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8035940803382664, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.717948717948718

Step Backward Feature Selection with LogisticRegression(random_state=0) to select 60 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8147991543340382, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7564102564102564

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7987315010570825, best hyperparameter: {'alpha': 0.5, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.726109936575053, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6538461538461539

Result of KNeighborsClassifier():
Best accuracy: 0.6734143763213531, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.5384615384615384

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7896405919661735, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8205128205128205

Result of SVC(random_state=0):
Best accuracy: 0.7802854122621565, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7948717948717948

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7804968287526427, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7945031712473571, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7051282051282052

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8035412262156448, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6923076923076923

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 60 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7827167019027484, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7849894291754758, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7564102564102564

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7169133192389006, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6153846153846154

Result of KNeighborsClassifier():
Best accuracy: 0.650369978858351, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7757399577167019, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=0):
Best accuracy: 0.7874207188160678, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.8205128205128205

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7804439746300211, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.782051282051282

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7764270613107822, best hyperparameter: {'max_depth': None, 'n_estimators': 30}
Accuracy on test set: 0.717948717948718

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7852008456659618, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7692307692307693

Step Backward Feature Selection with AdaBoostClassifier(random_state=0) to select 60 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7918076109936576, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.717948717948718

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7896405919661733, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7435897435897436

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.714323467230444, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 5}
Accuracy on test set: 0.6153846153846154

Result of KNeighborsClassifier():
Best accuracy: 0.6210359408033826, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.48717948717948717

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7805496828752643, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7307692307692307

Result of SVC(random_state=0):
Best accuracy: 0.7849365750528542, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8011627906976745, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6410256410256411

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7808668076109935, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.6410256410256411

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7966173361522199, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6282051282051282

Step Backward Feature Selection with LogisticRegression(random_state=0) to select 61 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8125264270613108, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8034355179704017, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.782051282051282

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7170190274841437, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6538461538461539

Result of KNeighborsClassifier():
Best accuracy: 0.6687632135306554, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5769230769230769

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7919133192389008, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8076923076923077

Result of SVC(random_state=0):
Best accuracy: 0.7804968287526428, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7873678646934461, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7435897435897436

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.785306553911205, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.6923076923076923

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7991014799154333, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7051282051282052

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 61 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7804439746300211, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7895348837209303, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7435897435897436

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7306553911205074, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.6153846153846154

Result of KNeighborsClassifier():
Best accuracy: 0.6529069767441861, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5897435897435898

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.768816067653277, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=0):
Best accuracy: 0.7828752642706129, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.8076923076923077

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7781183932346722, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7692307692307693

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7739957716701902, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.7051282051282052

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7830338266384778, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.6923076923076923

Step Backward Feature Selection with AdaBoostClassifier(random_state=0) to select 61 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7986257928118394, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7307692307692307

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7896934460887948, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7564102564102564

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7349365750528543, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.6923076923076923

Result of KNeighborsClassifier():
Best accuracy: 0.6186575052854122, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5256410256410257

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7759513742071882, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7307692307692307

Result of SVC(random_state=0):
Best accuracy: 0.7781183932346725, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7435897435897436

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8011627906976745, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6410256410256411

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.776215644820296, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.717948717948718

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7831395348837209, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.6410256410256411

Step Backward Feature Selection with LogisticRegression(random_state=0) to select 62 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8079809725158563, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7965644820295983, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7305496828752641, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 10}
Accuracy on test set: 0.6410256410256411

Result of KNeighborsClassifier():
Best accuracy: 0.6597251585623679, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5384615384615384

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7896405919661735, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8076923076923077

Result of SVC(random_state=0):
Best accuracy: 0.7782241014799155, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7435897435897436

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7781712473572939, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7307692307692307

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7830866807610993, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.6410256410256411

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7989429175475686, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6794871794871795

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 62 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7783298097251586, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7805496828752643, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7564102564102564

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7215116279069766, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6410256410256411

Result of KNeighborsClassifier():
Best accuracy: 0.6482029598308668, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5897435897435898

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7711945031712475, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=0):
Best accuracy: 0.7713002114164906, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7827167019027484, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.782051282051282

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7899577167019027, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.6666666666666666

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7876849894291753, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.6538461538461539

Step Backward Feature Selection with AdaBoostClassifier(random_state=0) to select 62 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7964059196617337, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7307692307692307

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7874207188160677, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7165961945031714, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 10}
Accuracy on test set: 0.6794871794871795

Result of KNeighborsClassifier():
Best accuracy: 0.6210359408033828, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.5384615384615384

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7806025369978858, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7307692307692307

Result of SVC(random_state=0):
Best accuracy: 0.7804439746300211, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.717948717948718

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8011627906976745, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6410256410256411

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.771723044397463, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.6666666666666666

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7900105708245243, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6538461538461539

Step Backward Feature Selection with LogisticRegression(random_state=0) to select 63 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8034355179704017, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7964587737843554, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.782051282051282

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7304439746300211, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 10}
Accuracy on test set: 0.6538461538461539

Result of KNeighborsClassifier():
Best accuracy: 0.6597780126849895, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5641025641025641

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7896405919661735, best hyperparameter: {'solver': 'lsqr'}
Accuracy on test set: 0.8076923076923077

Result of SVC(random_state=0):
Best accuracy: 0.7716701902748413, best hyperparameter: {'C': 1, 'kernel': 'linear'}
Accuracy on test set: 0.717948717948718

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7805496828752643, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7435897435897436

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7854122621564481, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.6666666666666666

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7853594080338266, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6538461538461539

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 63 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7806025369978858, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7782241014799155, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.782051282051282

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7191860465116279, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 10}
Accuracy on test set: 0.6538461538461539

Result of KNeighborsClassifier():
Best accuracy: 0.6321881606765328, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.5512820512820513

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7712473572938691, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=0):
Best accuracy: 0.7782241014799155, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7827167019027484, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.782051282051282

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.76723044397463, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.6666666666666666

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7832980972515855, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.7307692307692307

Step Backward Feature Selection with AdaBoostClassifier(random_state=0) to select 63 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7941331923890063, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7435897435897436

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7760570824524311, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.7307692307692307

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7166490486257928, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 5}
Accuracy on test set: 0.6282051282051282

Result of KNeighborsClassifier():
Best accuracy: 0.6233615221987316, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.5128205128205128

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7783298097251585, best hyperparameter: {'solver': 'lsqr'}
Accuracy on test set: 0.7307692307692307

Result of SVC(random_state=0):
Best accuracy: 0.7736257928118394, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7307692307692307

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8011627906976745, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6410256410256411

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7510570824524313, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6666666666666666

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7739957716701902, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.6282051282051282

Step Backward Feature Selection with LogisticRegression(random_state=0) to select 64 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7987843551797041, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8009513742071881, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.782051282051282

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7350422832980972, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 10}
Accuracy on test set: 0.6538461538461539

Result of KNeighborsClassifier():
Best accuracy: 0.6505813953488373, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.5512820512820513

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7849894291754758, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8076923076923077

Result of SVC(random_state=0):
Best accuracy: 0.7737315010570824, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.782875264270613, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7435897435897436

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7992071881606765, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6923076923076923

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.81284355179704, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7692307692307693

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 64 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7874735729386891, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7759513742071882, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7306553911205074, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.6410256410256411

Result of KNeighborsClassifier():
Best accuracy: 0.6322410147991544, best hyperparameter: {'n_neighbors': 5, 'weights': 'uniform'}
Accuracy on test set: 0.5897435897435898

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7735200845665963, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=0):
Best accuracy: 0.7896934460887948, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7827167019027484, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.8076923076923077

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7875792811839324, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.717948717948718

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7830338266384779, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7307692307692307

Step Backward Feature Selection with AdaBoostClassifier(random_state=0) to select 64 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7894820295983086, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7435897435897436

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7760570824524311, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.7307692307692307

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7166490486257928, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 5}
Accuracy on test set: 0.6410256410256411

Result of KNeighborsClassifier():
Best accuracy: 0.6233615221987316, best hyperparameter: {'n_neighbors': 5, 'weights': 'uniform'}
Accuracy on test set: 0.5128205128205128

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7714059196617337, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7307692307692307

Result of SVC(random_state=0):
Best accuracy: 0.7735200845665963, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.717948717948718

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8011627906976745, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6410256410256411

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7671247357293869, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.6282051282051282

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8035412262156448, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.6410256410256411

Step Backward Feature Selection with LogisticRegression(random_state=0) to select 65 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7987843551797041, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.798678646934461, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.782051282051282

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7170718816067654, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6666666666666666

Result of KNeighborsClassifier():
Best accuracy: 0.6573995771670191, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.5641025641025641

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7804439746300211, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8076923076923077

Result of SVC(random_state=0):
Best accuracy: 0.7804968287526428, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7781183932346722, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7435897435897436

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7852536997885835, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7051282051282052

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7944503171247357, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.7051282051282052

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 65 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7964059196617337, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.791860465116279, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.782051282051282

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7283298097251586, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6538461538461539

Result of KNeighborsClassifier():
Best accuracy: 0.6459302325581395, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.5769230769230769

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7713002114164905, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8076923076923077

Result of SVC(random_state=0):
Best accuracy: 0.7849365750528541, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7895877378435519, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.782051282051282

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7717758985200844, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.717948717948718

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7968816067653276, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.717948717948718

Step Backward Feature Selection with AdaBoostClassifier(random_state=0) to select 65 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7894820295983086, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7435897435897436

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7783298097251585, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.7307692307692307

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7192389006342493, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.5641025641025641

Result of KNeighborsClassifier():
Best accuracy: 0.6255285412262157, best hyperparameter: {'n_neighbors': 9, 'weights': 'uniform'}
Accuracy on test set: 0.5641025641025641

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.773678646934461, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.717948717948718

Result of SVC(random_state=0):
Best accuracy: 0.7735200845665963, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.717948717948718

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8011627906976745, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6410256410256411

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7738900634249471, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.6153846153846154

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7877906976744186, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.6282051282051282

Step Backward Feature Selection with LogisticRegression(random_state=0) to select 66 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7987843551797041, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7964059196617337, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7395877378435517, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 10}
Accuracy on test set: 0.6153846153846154

Result of KNeighborsClassifier():
Best accuracy: 0.659830866807611, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6025641025641025

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7781183932346722, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8205128205128205

Result of SVC(random_state=0):
Best accuracy: 0.787262156448203, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7781712473572939, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.796723044397463, best hyperparameter: {'max_depth': 10, 'n_estimators': 30}
Accuracy on test set: 0.7051282051282052

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8105708245243128, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.6794871794871795

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 66 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7964059196617337, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.791860465116279, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.782051282051282

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7260570824524312, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 10}
Accuracy on test set: 0.6025641025641025

Result of KNeighborsClassifier():
Best accuracy: 0.6458773784355181, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7712473572938688, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=0):
Best accuracy: 0.7849365750528541, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.789587737843552, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.782051282051282

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7737843551797041, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6410256410256411

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7830866807610993, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.6794871794871795

Step Backward Feature Selection with AdaBoostClassifier(random_state=0) to select 66 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7849365750528541, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7564102564102564

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7714059196617337, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7281183932346724, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.717948717948718

Result of KNeighborsClassifier():
Best accuracy: 0.6277484143763215, best hyperparameter: {'n_neighbors': 5, 'weights': 'uniform'}
Accuracy on test set: 0.5128205128205128

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7598837209302326, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.717948717948718

Result of SVC(random_state=0):
Best accuracy: 0.7735200845665963, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.7307692307692307

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8011627906976745, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6410256410256411

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7717758985200845, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.6923076923076923

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8038054968287526, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.6538461538461539

Step Backward Feature Selection with LogisticRegression(random_state=0) to select 67 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7987843551797041, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.798678646934461, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7329281183932347, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6410256410256411

Result of KNeighborsClassifier():
Best accuracy: 0.6643234672304439, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.5897435897435898

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7781712473572939, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8076923076923077

Result of SVC(random_state=0):
Best accuracy: 0.7644291754756872, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7711945031712475, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7435897435897436

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7876321353065538, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.7307692307692307

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.801321353065539, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.717948717948718

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 67 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7964059196617337, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7851479915433404, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7351479915433403, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.6538461538461539

Result of KNeighborsClassifier():
Best accuracy: 0.6298625792811839, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5769230769230769

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7690274841437632, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=0):
Best accuracy: 0.7849894291754758, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7435897435897436

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7849894291754758, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.782051282051282

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7785940803382664, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.717948717948718

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7830338266384779, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7564102564102564

Step Backward Feature Selection with AdaBoostClassifier(random_state=0) to select 67 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7849365750528542, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.766860465116279, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.7307692307692307

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7234672304439747, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 10}
Accuracy on test set: 0.6794871794871795

Result of KNeighborsClassifier():
Best accuracy: 0.627906976744186, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.5641025641025641

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7621564482029599, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7307692307692307

Result of SVC(random_state=0):
Best accuracy: 0.7621035940803383, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7307692307692307

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8011627906976745, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6410256410256411

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.783245243128964, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.6666666666666666

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7715644820295982, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.6025641025641025

Step Backward Feature Selection with LogisticRegression(random_state=0) to select 68 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7987843551797041, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7964059196617337, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7304968287526428, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 10}
Accuracy on test set: 0.6410256410256411

Result of KNeighborsClassifier():
Best accuracy: 0.6690274841437633, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5897435897435898

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7758456659619452, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8076923076923077

Result of SVC(random_state=0):
Best accuracy: 0.7689217758985201, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7735200845665963, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7307692307692307

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7900634249471459, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.7051282051282052

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7901162790697673, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7307692307692307

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 68 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7918604651162792, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7828224101479916, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.782051282051282

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7352536997885835, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.6538461538461539

Result of KNeighborsClassifier():
Best accuracy: 0.6278541226215645, best hyperparameter: {'n_neighbors': 9, 'weights': 'uniform'}
Accuracy on test set: 0.5641025641025641

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7713002114164905, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=0):
Best accuracy: 0.7804439746300214, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7895348837209303, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.782051282051282

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.771723044397463, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.6794871794871795

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7831923890063424, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7051282051282052

Step Backward Feature Selection with AdaBoostClassifier(random_state=0) to select 68 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.78276955602537, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7564102564102564

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7690803382663848, best hyperparameter: {'alpha': 5, 'max_iter': None}
Accuracy on test set: 0.7435897435897436

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7165961945031712, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 5}
Accuracy on test set: 0.6282051282051282

Result of KNeighborsClassifier():
Best accuracy: 0.6232558139534884, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.5256410256410257

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7644291754756871, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.717948717948718

Result of SVC(random_state=0):
Best accuracy: 0.7644291754756871, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7307692307692307

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8011627906976745, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6410256410256411

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7715116279069767, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6153846153846154

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.760306553911205, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.6410256410256411

Step Backward Feature Selection with LogisticRegression(random_state=0) to select 69 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7987843551797041, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7941331923890065, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7258985200845667, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.6282051282051282

Result of KNeighborsClassifier():
Best accuracy: 0.6596723044397463, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5512820512820513

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7758985200845666, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=0):
Best accuracy: 0.7713530655391121, best hyperparameter: {'C': 1, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7689746300211416, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7435897435897436

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7806025369978858, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7051282051282052

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8036997885835095, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.7051282051282052

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 69 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.787262156448203, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7850951374207189, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.782051282051282

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.739693446088795, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 10}
Accuracy on test set: 0.6153846153846154

Result of KNeighborsClassifier():
Best accuracy: 0.6460887949260042, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5897435897435898

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7668076109936576, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=0):
Best accuracy: 0.7714059196617337, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.787262156448203, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.782051282051282

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7990486257928118, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.6923076923076923

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8035940803382664, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7307692307692307

Step Backward Feature Selection with AdaBoostClassifier(random_state=0) to select 69 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7804439746300211, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.766754756871036, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7143763213530656, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.7051282051282052

Result of KNeighborsClassifier():
Best accuracy: 0.6301268498942918, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.5641025641025641

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.766754756871036, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.717948717948718

Result of SVC(random_state=0):
Best accuracy: 0.7576109936575053, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7307692307692307

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8011627906976745, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6410256410256411

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.780813953488372, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.6666666666666666

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7807610993657506, best hyperparameter: {'max_depth': None, 'n_estimators': 30}
Accuracy on test set: 0.7051282051282052

Step Backward Feature Selection with LogisticRegression(random_state=0) to select 70 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7965116279069768, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7895877378435519, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7238900634249471, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6282051282051282

Result of KNeighborsClassifier():
Best accuracy: 0.6598837209302326, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.5769230769230769

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7781712473572939, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=0):
Best accuracy: 0.7623150105708246, best hyperparameter: {'C': 1, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7643763213530657, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7435897435897436

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7691331923890063, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6794871794871795

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7851479915433404, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.6923076923076923

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 70 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7895877378435519, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7851479915433404, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.782051282051282

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7260042283298096, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.6666666666666666

Result of KNeighborsClassifier():
Best accuracy: 0.6573995771670191, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5897435897435898

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.762262156448203, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=0):
Best accuracy: 0.7713002114164904, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7940274841437633, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7692307692307693

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7920190274841437, best hyperparameter: {'max_depth': None, 'n_estimators': 30}
Accuracy on test set: 0.6666666666666666

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7900634249471459, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.717948717948718

Step Backward Feature Selection with AdaBoostClassifier(random_state=0) to select 70 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7736257928118395, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7598837209302326, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7142706131078225, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 5}
Accuracy on test set: 0.6153846153846154

Result of KNeighborsClassifier():
Best accuracy: 0.6232029598308669, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.5897435897435898

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7622093023255815, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.717948717948718

Result of SVC(random_state=0):
Best accuracy: 0.7757928118393236, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7307692307692307

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8011627906976745, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6410256410256411

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7671775898520083, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.6538461538461539

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.760306553911205, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.6538461538461539

Step Backward Feature Selection with LogisticRegression(random_state=0) to select 71 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7941860465116279, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7827167019027484, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7145877378435518, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 10}
Accuracy on test set: 0.6282051282051282

Result of KNeighborsClassifier():
Best accuracy: 0.6596723044397464, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5641025641025641

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7758985200845666, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=0):
Best accuracy: 0.7644820295983086, best hyperparameter: {'C': 1, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7689217758985201, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7738372093023255, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6666666666666666

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7785412262156447, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.6666666666666666

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 71 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7850422832980973, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7828224101479915, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.782051282051282

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7101479915433404, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6538461538461539

Result of KNeighborsClassifier():
Best accuracy: 0.6482029598308668, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5897435897435898

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7691331923890063, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=0):
Best accuracy: 0.7714059196617337, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7895348837209303, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.782051282051282

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7648520084566595, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.7051282051282052

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7920718816067653, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.6794871794871795

Step Backward Feature Selection with AdaBoostClassifier(random_state=0) to select 71 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.771247357293869, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7644820295983088, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7435897435897436

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7236786469344609, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 10}
Accuracy on test set: 0.6923076923076923

Result of KNeighborsClassifier():
Best accuracy: 0.6391120507399577, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6025641025641025

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7576109936575054, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.717948717948718

Result of SVC(random_state=0):
Best accuracy: 0.7691331923890065, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.717948717948718

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8011627906976745, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6410256410256411

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7670718816067653, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.6666666666666666

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7696617336152218, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.6410256410256411

Step Backward Feature Selection with LogisticRegression(random_state=0) to select 72 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7919133192389006, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7850422832980973, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7191331923890063, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.6794871794871795

Result of KNeighborsClassifier():
Best accuracy: 0.6482029598308668, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6025641025641025

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7736257928118393, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=0):
Best accuracy: 0.7553382663847781, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7435897435897436

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7621035940803382, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7692307692307693

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7945031712473571, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.717948717948718

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7990486257928117, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7307692307692307

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 72 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7873678646934461, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8333333333333334

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7827167019027484, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.782051282051282

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7307082452431288, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6410256410256411

Result of KNeighborsClassifier():
Best accuracy: 0.6597251585623679, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5769230769230769

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7667019027484144, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=0):
Best accuracy: 0.7689746300211417, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7918076109936575, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7692307692307693

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.773784355179704, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.7307692307692307

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7809196617336152, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.6794871794871795

Step Backward Feature Selection with AdaBoostClassifier(random_state=0) to select 72 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7735729386892178, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7598837209302326, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7564102564102564

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.714323467230444, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.6923076923076923

Result of KNeighborsClassifier():
Best accuracy: 0.6345137420718816, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6025641025641025

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7599365750528542, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.717948717948718

Result of SVC(random_state=0):
Best accuracy: 0.7714059196617337, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7051282051282052

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8011627906976745, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6410256410256411

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7510570824524313, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.6794871794871795

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7716173361522198, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6794871794871795

Step Backward Feature Selection with LogisticRegression(random_state=0) to select 73 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7873678646934461, best hyperparameter: {'C': 1, 'max_iter': 100}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7850422832980973, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7191860465116279, best hyperparameter: {'class_weight': None, 'max_depth': None}
Accuracy on test set: 0.6025641025641025

Result of KNeighborsClassifier():
Best accuracy: 0.6436046511627908, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7758456659619452, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=0):
Best accuracy: 0.7553382663847781, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7435897435897436

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7598308668076111, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7806553911205074, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.7307692307692307

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7901162790697673, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6666666666666666

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 73 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7873150105708246, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7850422832980973, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.782051282051282

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7260042283298097, best hyperparameter: {'class_weight': None, 'max_depth': None}
Accuracy on test set: 0.5769230769230769

Result of KNeighborsClassifier():
Best accuracy: 0.6528012684989429, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5384615384615384

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7735200845665963, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=0):
Best accuracy: 0.7713002114164904, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.787262156448203, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.782051282051282

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7853594080338266, best hyperparameter: {'max_depth': 10, 'n_estimators': 30}
Accuracy on test set: 0.6666666666666666

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7876321353065538, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.7051282051282052

Step Backward Feature Selection with AdaBoostClassifier(random_state=0) to select 73 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7713530655391121, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7622621564482029, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7564102564102564

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7213530655391122, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.7051282051282052

Result of KNeighborsClassifier():
Best accuracy: 0.6321881606765328, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6025641025641025

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7575581395348838, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.717948717948718

Result of SVC(random_state=0):
Best accuracy: 0.7714059196617337, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7307692307692307

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8011627906976745, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6410256410256411

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7626321353065538, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6282051282051282

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7648520084566595, best hyperparameter: {'max_depth': 10, 'n_estimators': 30}
Accuracy on test set: 0.717948717948718

Step Backward Feature Selection with LogisticRegression(random_state=0) to select 74 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.78276955602537, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.78276955602537, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7171247357293868, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6282051282051282

Result of KNeighborsClassifier():
Best accuracy: 0.6390063424947147, best hyperparameter: {'n_neighbors': 5, 'weights': 'uniform'}
Accuracy on test set: 0.5512820512820513

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.771247357293869, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=0):
Best accuracy: 0.7576109936575054, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7435897435897436

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7552854122621564, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7647463002114165, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7051282051282052

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7875264270613108, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7435897435897436

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 74 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7850422832980973, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7873678646934461, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.782051282051282

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7259513742071884, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 10}
Accuracy on test set: 0.6410256410256411

Result of KNeighborsClassifier():
Best accuracy: 0.6366807610993657, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5769230769230769

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.771247357293869, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=0):
Best accuracy: 0.7781712473572939, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7803911205073997, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.782051282051282

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7716701902748413, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6410256410256411

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7696088794926004, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.717948717948718

Step Backward Feature Selection with AdaBoostClassifier(random_state=0) to select 74 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7713530655391121, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7690803382663849, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7564102564102564

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7234672304439747, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.6794871794871795

Result of KNeighborsClassifier():
Best accuracy: 0.6185517970401693, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.5897435897435898

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7552325581395349, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.717948717948718

Result of SVC(random_state=0):
Best accuracy: 0.7737315010570823, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7307692307692307

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8011627906976745, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6410256410256411

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.771828752642706, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.6153846153846154

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7693974630021142, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.717948717948718

Step Backward Feature Selection with LogisticRegression(random_state=0) to select 75 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.78276955602537, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.78276955602537, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7168076109936575, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.6666666666666666

Result of KNeighborsClassifier():
Best accuracy: 0.6458245243128964, best hyperparameter: {'n_neighbors': 5, 'weights': 'uniform'}
Accuracy on test set: 0.5769230769230769

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7689746300211417, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=0):
Best accuracy: 0.7552854122621564, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7435897435897436

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7598308668076111, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7692307692307693

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7782769556025371, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6666666666666666

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7873150105708246, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.6666666666666666

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 75 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7804439746300211, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.8205128205128205

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7850951374207188, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7564102564102564

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.725845665961945, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.6025641025641025

Result of KNeighborsClassifier():
Best accuracy: 0.6345137420718816, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5641025641025641

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7757928118393236, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=0):
Best accuracy: 0.7622093023255815, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7782769556025371, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.5769230769230769

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7693974630021142, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7051282051282052

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7763213530655391, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.7564102564102564

Step Backward Feature Selection with AdaBoostClassifier(random_state=0) to select 75 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7598837209302326, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7690803382663849, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7564102564102564

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.725845665961945, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 5}
Accuracy on test set: 0.6282051282051282

Result of KNeighborsClassifier():
Best accuracy: 0.6025369978858351, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5128205128205128

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7552325581395349, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.717948717948718

Result of SVC(random_state=0):
Best accuracy: 0.7669133192389005, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7307692307692307

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7965116279069767, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6410256410256411

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7465644820295984, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.6538461538461539

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7923890063424947, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.6410256410256411

Step Backward Feature Selection with LogisticRegression(random_state=0) to select 76 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7873150105708246, best hyperparameter: {'C': 1, 'max_iter': 100}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.789587737843552, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7190803382663848, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.6538461538461539

Result of KNeighborsClassifier():
Best accuracy: 0.6436575052854122, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5769230769230769

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7803911205073997, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=0):
Best accuracy: 0.7508456659619451, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7643763213530657, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7648520084566595, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.6666666666666666

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7761627906976744, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.6923076923076923

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 76 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7804968287526428, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7828224101479917, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7167019027484145, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.5897435897435898

Result of KNeighborsClassifier():
Best accuracy: 0.6345137420718816, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6025641025641025

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7735729386892178, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=0):
Best accuracy: 0.766754756871036, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7760570824524311, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.5769230769230769

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7649577167019027, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.6794871794871795

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7668604651162791, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.6794871794871795

Step Backward Feature Selection with AdaBoostClassifier(random_state=0) to select 76 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7621564482029598, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7644820295983088, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7143763213530656, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.6923076923076923

Result of KNeighborsClassifier():
Best accuracy: 0.6140063424947146, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5384615384615384

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7529598308668076, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.717948717948718

Result of SVC(random_state=0):
Best accuracy: 0.7669133192389006, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7435897435897436

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7942389006342495, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6410256410256411

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7534355179704016, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6794871794871795

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7533298097251585, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.717948717948718

Step Backward Feature Selection with LogisticRegression(random_state=0) to select 77 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7873150105708246, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.789587737843552, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7124735729386893, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6538461538461539

Result of KNeighborsClassifier():
Best accuracy: 0.6484143763213531, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5769230769230769

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7803382663847781, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=0):
Best accuracy: 0.7508456659619451, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7643763213530657, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.771723044397463, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.6923076923076923

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7808668076109937, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.7051282051282052

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 77 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7827167019027484, best hyperparameter: {'C': 0.2, 'max_iter': 50}
Accuracy on test set: 0.8333333333333334

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.778276955602537, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.728276955602537, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.6153846153846154

Result of KNeighborsClassifier():
Best accuracy: 0.6367336152219873, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7735200845665963, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=0):
Best accuracy: 0.7644291754756871, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7948717948717948

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7738372093023255, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.5769230769230769

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7602536997885836, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.6410256410256411

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7761627906976744, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.717948717948718

Step Backward Feature Selection with AdaBoostClassifier(random_state=0) to select 77 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7598308668076109, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7644820295983088, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.782051282051282

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7029069767441861, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 5}
Accuracy on test set: 0.6410256410256411

Result of KNeighborsClassifier():
Best accuracy: 0.6162790697674418, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5384615384615384

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.743816067653277, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.717948717948718

Result of SVC(random_state=0):
Best accuracy: 0.7645348837209303, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7435897435897436

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7942389006342495, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6410256410256411

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7536997885835095, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.717948717948718

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7579809725158562, best hyperparameter: {'max_depth': 10, 'n_estimators': 50}
Accuracy on test set: 0.6923076923076923

Step Backward Feature Selection with LogisticRegression(random_state=0) to select 78 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7873150105708246, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7849894291754758, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7350422832980973, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.6538461538461539

Result of KNeighborsClassifier():
Best accuracy: 0.6438689217758986, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5769230769230769

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7826109936575053, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=0):
Best accuracy: 0.755338266384778, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7435897435897436

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7621035940803382, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7692307692307693

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7672832980972515, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.6923076923076923

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8081923890063424, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.7051282051282052

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 78 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7804968287526428, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.77838266384778, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7305496828752641, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.5769230769230769

Result of KNeighborsClassifier():
Best accuracy: 0.6366807610993658, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.5256410256410257

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7735729386892178, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=0):
Best accuracy: 0.7507928118393234, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7948717948717948

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7735729386892178, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.782051282051282

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7718816067653277, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.6923076923076923

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7741014799154333, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.7051282051282052

Step Backward Feature Selection with AdaBoostClassifier(random_state=0) to select 78 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7576109936575053, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7644291754756871, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.709830866807611, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 5}
Accuracy on test set: 0.6410256410256411

Result of KNeighborsClassifier():
Best accuracy: 0.6163847780126851, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5512820512820513

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7598837209302326, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7307692307692307

Result of SVC(random_state=0):
Best accuracy: 0.7759513742071882, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7307692307692307

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7942389006342495, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6410256410256411

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.755813953488372, best hyperparameter: {'max_depth': None, 'n_estimators': 80}
Accuracy on test set: 0.6666666666666666

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7716701902748413, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.6282051282051282

Step Backward Feature Selection with LogisticRegression(random_state=0) to select 79 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7873150105708246, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7849894291754758, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7281712473572939, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.6282051282051282

Result of KNeighborsClassifier():
Best accuracy: 0.6323467230443975, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7802854122621564, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=0):
Best accuracy: 0.7531183932346723, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7689217758985201, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7716701902748413, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.6794871794871795

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7670718816067653, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.6923076923076923

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 79 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7827167019027484, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7919133192389008, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7564102564102564

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7488372093023254, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 10}
Accuracy on test set: 0.6153846153846154

Result of KNeighborsClassifier():
Best accuracy: 0.6413319238900634, best hyperparameter: {'n_neighbors': 7, 'weights': 'uniform'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7758456659619452, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=0):
Best accuracy: 0.7599365750528542, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.769291754756871, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6153846153846154

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7603594080338267, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7051282051282052

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7740486257928119, best hyperparameter: {'max_depth': 10, 'n_estimators': 30}
Accuracy on test set: 0.7692307692307693

Step Backward Feature Selection with AdaBoostClassifier(random_state=0) to select 79 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7644291754756871, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.782051282051282

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7621035940803382, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.7307692307692307

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7190803382663848, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 10}
Accuracy on test set: 0.6153846153846154

Result of KNeighborsClassifier():
Best accuracy: 0.6231501057082452, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5128205128205128

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7644291754756872, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7307692307692307

Result of SVC(random_state=0):
Best accuracy: 0.7644820295983086, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7435897435897436

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7942389006342495, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6410256410256411

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7466701902748414, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.6538461538461539

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7579809725158562, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6410256410256411

Step Backward Feature Selection with LogisticRegression(random_state=0) to select 80 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7873150105708246, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7850422832980973, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.8205128205128205

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.728171247357294, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 10}
Accuracy on test set: 0.6666666666666666

Result of KNeighborsClassifier():
Best accuracy: 0.6369450317124736, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.5641025641025641

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7848837209302326, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=0):
Best accuracy: 0.7531183932346723, best hyperparameter: {'C': 0.2, 'kernel': 'linear'}
Accuracy on test set: 0.7692307692307693

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7689217758985201, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7625792811839324, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6666666666666666

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7693974630021142, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.6794871794871795

Step Backward Feature Selection with RandomForestClassifier(n_estimators=20, random_state=0) to select 80 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7781712473572939, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.8076923076923077

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7918604651162792, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7395348837209303, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.5769230769230769

Result of KNeighborsClassifier():
Best accuracy: 0.6391120507399577, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.48717948717948717

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.771247357293869, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=0):
Best accuracy: 0.7531183932346723, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7435897435897436

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7621035940803382, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7692307692307693

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7581395348837209, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.717948717948718

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7671247357293869, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7307692307692307

Step Backward Feature Selection with AdaBoostClassifier(random_state=0) to select 80 features completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7667019027484144, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7621035940803382, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.7692307692307693

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7189217758985201, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.6282051282051282

Result of KNeighborsClassifier():
Best accuracy: 0.6208245243128964, best hyperparameter: {'n_neighbors': 7, 'weights': 'distance'}
Accuracy on test set: 0.5512820512820513

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7598308668076111, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7307692307692307

Result of SVC(random_state=0):
Best accuracy: 0.7621564482029599, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7435897435897436

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7919661733615222, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6410256410256411

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7375792811839323, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.6410256410256411

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7488900634249471, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.6666666666666666

Select Feature Importance with LogisticRegression(C=1000, random_state=0) completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8171247357293868, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8148520084566595, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7371035940803383, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6666666666666666

Result of KNeighborsClassifier():
Best accuracy: 0.694291754756871, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6153846153846154

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8011627906976745, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.8205128205128205

Result of SVC(random_state=0):
Best accuracy: 0.8261627906976743, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.8076923076923077

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.803276955602537, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7692307692307693

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.8171247357293868, best hyperparameter: {'max_depth': 10, 'n_estimators': 80}
Accuracy on test set: 0.717948717948718

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8172832980972515, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.717948717948718

Select Feature Importance with DecisionTreeClassifier(random_state=0) completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7920718816067653, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7307692307692307

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7988372093023255, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7534355179704018, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6410256410256411

Result of KNeighborsClassifier():
Best accuracy: 0.7216173361522199, best hyperparameter: {'n_neighbors': 9, 'weights': 'distance'}
Accuracy on test set: 0.6410256410256411

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7806025369978858, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=0):
Best accuracy: 0.7672832980972515, best hyperparameter: {'C': 1, 'kernel': 'poly'}
Accuracy on test set: 0.6794871794871795

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7899048625792812, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.6923076923076923

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.810306553911205, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.6410256410256411

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7923890063424948, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.6923076923076923

Select Feature Importance with RandomForestClassifier(random_state=0) completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8172304439746301, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8150105708245243, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.782051282051282

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7487315010570825, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 5}
Accuracy on test set: 0.6923076923076923

Result of KNeighborsClassifier():
Best accuracy: 0.7354651162790697, best hyperparameter: {'n_neighbors': 9, 'weights': 'uniform'}
Accuracy on test set: 0.6794871794871795

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8012684989429175, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7564102564102564

Result of SVC(random_state=0):
Best accuracy: 0.7943974630021142, best hyperparameter: {'C': 0.05, 'kernel': 'linear'}
Accuracy on test set: 0.7564102564102564

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7943446088794925, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7564102564102564

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7900634249471459, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.6923076923076923

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.812737843551797, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7564102564102564

Select Feature Importance with AdaBoostClassifier(random_state=0) completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7781712473572939, best hyperparameter: {'C': 0.05, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7760570824524311, best hyperparameter: {'alpha': 100, 'max_iter': None}
Accuracy on test set: 0.8076923076923077

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7508456659619451, best hyperparameter: {'class_weight': 'balanced', 'max_depth': 5}
Accuracy on test set: 0.6410256410256411

Result of KNeighborsClassifier():
Best accuracy: 0.698678646934461, best hyperparameter: {'n_neighbors': 9, 'weights': 'uniform'}
Accuracy on test set: 0.5256410256410257

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7668076109936577, best hyperparameter: {'solver': 'lsqr'}
Accuracy on test set: 0.7692307692307693

Result of SVC(random_state=0):
Best accuracy: 0.789693446088795, best hyperparameter: {'C': 1, 'kernel': 'rbf'}
Accuracy on test set: 0.782051282051282

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7736786469344609, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7692307692307693

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.8126321353065539, best hyperparameter: {'max_depth': None, 'n_estimators': 50}
Accuracy on test set: 0.6923076923076923

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8219873150105709, best hyperparameter: {'max_depth': 10, 'n_estimators': 100}
Accuracy on test set: 0.7435897435897436

Recursive Feature Addition with LogisticRegression(random_state=0) completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8310253699788583, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.7948717948717948

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8219873150105709, best hyperparameter: {'alpha': 10, 'max_iter': None}
Accuracy on test set: 0.7948717948717948

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7693974630021142, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.7051282051282052

Result of KNeighborsClassifier():
Best accuracy: 0.801109936575053, best hyperparameter: {'n_neighbors': 9, 'weights': 'uniform'}
Accuracy on test set: 0.6794871794871795

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.8104122621564482, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7948717948717948

Result of SVC(random_state=0):
Best accuracy: 0.8238900634249472, best hyperparameter: {'C': 1, 'kernel': 'rbf'}
Accuracy on test set: 0.717948717948718

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8196088794926004, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 10}
Accuracy on test set: 0.7692307692307693

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.8148520084566595, best hyperparameter: {'max_depth': 5, 'n_estimators': 80}
Accuracy on test set: 0.7307692307692307

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.8125792811839323, best hyperparameter: {'max_depth': 5, 'n_estimators': 100}
Accuracy on test set: 0.7307692307692307

Recursive Feature Addition with DecisionTreeClassifier(random_state=0) completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.789799154334038, best hyperparameter: {'C': 1, 'max_iter': 50}
Accuracy on test set: 0.717948717948718

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7715116279069767, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.7307692307692307

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7921247357293868, best hyperparameter: {'class_weight': None, 'max_depth': None}
Accuracy on test set: 0.5897435897435898

Result of KNeighborsClassifier():
Best accuracy: 0.7510042283298098, best hyperparameter: {'n_neighbors': 1, 'weights': 'uniform'}
Accuracy on test set: 0.6025641025641025

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7714059196617337, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7435897435897436

Result of SVC(random_state=0):
Best accuracy: 0.7760570824524311, best hyperparameter: {'C': 0.1, 'kernel': 'linear'}
Accuracy on test set: 0.717948717948718

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7807082452431289, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 50}
Accuracy on test set: 0.7051282051282052

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7670190274841436, best hyperparameter: {'max_depth': 10, 'n_estimators': 30}
Accuracy on test set: 0.6666666666666666

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7761099365750528, best hyperparameter: {'max_depth': 5, 'n_estimators': 50}
Accuracy on test set: 0.717948717948718

Recursive Feature Addition with RandomForestClassifier(random_state=0) completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.8193446088794925, best hyperparameter: {'C': 5, 'max_iter': 50}
Accuracy on test set: 0.7692307692307693

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.8126321353065539, best hyperparameter: {'alpha': 0.1, 'max_iter': None}
Accuracy on test set: 0.7564102564102564

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7556553911205074, best hyperparameter: {'class_weight': None, 'max_depth': 5}
Accuracy on test set: 0.6666666666666666

Result of KNeighborsClassifier():
Best accuracy: 0.7942389006342496, best hyperparameter: {'n_neighbors': 9, 'weights': 'uniform'}
Accuracy on test set: 0.6923076923076923

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.819397463002114, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.782051282051282

Result of SVC(random_state=0):
Best accuracy: 0.8148520084566595, best hyperparameter: {'C': 1, 'kernel': 'rbf'}
Accuracy on test set: 0.7435897435897436

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.8011099365750528, best hyperparameter: {'estimator': LogisticRegression(), 'n_estimators': 30}
Accuracy on test set: 0.717948717948718

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.8080338266384777, best hyperparameter: {'max_depth': 5, 'n_estimators': 80}
Accuracy on test set: 0.717948717948718

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7988900634249472, best hyperparameter: {'max_depth': None, 'n_estimators': 100}
Accuracy on test set: 0.7564102564102564

Recursive Feature Addition with AdaBoostClassifier(random_state=0) completed. Start tuning hyperparameters:
Result of LogisticRegression(random_state=0):
Best accuracy: 0.7669133192389005, best hyperparameter: {'C': 0.1, 'max_iter': 50}
Accuracy on test set: 0.7435897435897436

Result of RidgeClassifier(random_state=0):
Best accuracy: 0.7623678646934462, best hyperparameter: {'alpha': 50, 'max_iter': None}
Accuracy on test set: 0.7307692307692307

Result of DecisionTreeClassifier(random_state=0):
Best accuracy: 0.7102008456659619, best hyperparameter: {'class_weight': 'balanced', 'max_depth': None}
Accuracy on test set: 0.6538461538461539

Result of KNeighborsClassifier():
Best accuracy: 0.7854122621564482, best hyperparameter: {'n_neighbors': 5, 'weights': 'distance'}
Accuracy on test set: 0.6410256410256411

Result of LinearDiscriminantAnalysis():
Best accuracy: 0.7509513742071882, best hyperparameter: {'solver': 'svd'}
Accuracy on test set: 0.7435897435897436

Result of SVC(random_state=0):
Best accuracy: 0.7739429175475687, best hyperparameter: {'C': 5, 'kernel': 'poly'}
Accuracy on test set: 0.6538461538461539

Result of AdaBoostClassifier(random_state=0):
Best accuracy: 0.7828224101479917, best hyperparameter: {'estimator': None, 'n_estimators': 50}
Accuracy on test set: 0.6794871794871795

Result of RandomForestClassifier(random_state=0):
Best accuracy: 0.7534355179704018, best hyperparameter: {'max_depth': 10, 'n_estimators': 10}
Accuracy on test set: 0.6538461538461539

Result of ExtraTreesClassifier(random_state=0):
Best accuracy: 0.7741014799154333, best hyperparameter: {'max_depth': 10, 'n_estimators': 30}
Accuracy on test set: 0.6538461538461539

